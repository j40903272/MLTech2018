{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dada/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/dada/.local/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn import cross_validation, grid_search, metrics, ensemble\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>age</th>\n",
       "      <th>loc</th>\n",
       "      <th>author</th>\n",
       "      <th>years</th>\n",
       "      <th>publisher</th>\n",
       "      <th>foldID</th>\n",
       "      <th>surprise</th>\n",
       "      <th>FM</th>\n",
       "      <th>keras</th>\n",
       "      <th>XGBRegressor</th>\n",
       "      <th>XGBClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>133745</td>\n",
       "      <td>6329</td>\n",
       "      <td>47.0</td>\n",
       "      <td>18959</td>\n",
       "      <td>41855</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>560</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>21147</td>\n",
       "      <td>75160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9894</td>\n",
       "      <td>37869</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4132</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>13559</td>\n",
       "      <td>886</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4962</td>\n",
       "      <td>62104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11567</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>31266</td>\n",
       "      <td>57887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15860</td>\n",
       "      <td>45272</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>2678</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>80349</td>\n",
       "      <td>46556</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8588</td>\n",
       "      <td>11258</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>4553</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Book-Rating    ISBN  User-ID   age    loc  author   years  publisher  \\\n",
       "0          8.0  133745     6329  47.0  18959   41855  1992.0        560   \n",
       "1         10.0   21147    75160   0.0   9894   37869  2001.0       4132   \n",
       "2          8.0   13559      886  29.0   4962   62104     0.0      11567   \n",
       "3         10.0   31266    57887   0.0  15860   45272  1997.0       2678   \n",
       "4          9.0   80349    46556  45.0   8588   11258  2000.0       4553   \n",
       "\n",
       "   foldID  surprise   FM  keras  XGBRegressor  XGBClassifier  \n",
       "0       3       7.0  7.0      8             7              7  \n",
       "1       3       8.0  7.0      8             8              8  \n",
       "2       4       8.0  8.0      8             8              8  \n",
       "3       5       8.0  7.0      8             7              8  \n",
       "4       4      10.0  8.0     10             9             10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_meta = pd.read_csv('stack/train_meta3.csv')\n",
    "test_meta = pd.read_csv('stack/test_meta3.csv')\n",
    "train_meta = train_meta.drop(columns=['Unnamed: 0'])\n",
    "test_meta = test_meta.drop(columns=['Unnamed: 0'])\n",
    "train_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260202 entries, 0 to 260201\n",
      "Data columns (total 14 columns):\n",
      "Book-Rating      260202 non-null float64\n",
      "ISBN             260202 non-null int64\n",
      "User-ID          260202 non-null int64\n",
      "age              260202 non-null float64\n",
      "loc              260202 non-null int64\n",
      "author           260202 non-null int64\n",
      "years            260202 non-null float64\n",
      "publisher        260202 non-null int64\n",
      "foldID           260202 non-null int64\n",
      "surprise         260202 non-null float64\n",
      "FM               260202 non-null float64\n",
      "keras            260202 non-null int64\n",
      "XGBRegressor     260202 non-null int64\n",
      "XGBClassifier    260202 non-null int64\n",
      "dtypes: float64(5), int64(9)\n",
      "memory usage: 27.8 MB\n"
     ]
    }
   ],
   "source": [
    "train_meta.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdUAAAFwCAYAAADuaOGqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xm8W1W9/vHP04EWKCCTiAwWsIAI\npS1lkqpFkQuigIKC4k8RsKIgosIVr8jFqle8qEwCUhQZBEFRoCoyCBSxCrR0gBZEEFDmK/NcaM/3\n98daadNDzpTsfZKT87z72q8me+9890pOkpU1KyIwMzOzxg1pdgLMzMzahTNVMzOzgjhTNTMzK4gz\nVTMzs4I4UzUzMyuIM1UzM7OCOFM1MzMriDNVMzOzgjhTNTMzK8iwZiegXb32xH2lTFV1yoTjygjL\niJIm1nrT4vJm7HpsmEqJ+2o5YXlDRzlxAZ4p6efxCiX9+Q6Y8GA5gYEL52xQStyPjysnzUNXKq9s\ns/iZct50a119Y6Gfknq/L4evtXFJn9b6uaRqZmZWEJdUzcysuTqWNDsFhXGmamZmzRUlto30M2eq\nZmbWXB3OVM3MzAoRbVRSLbSjkqQlkuZJmi9pjqR31BlnsqTf9eK8GZLuztebJWlcLx5zpKSVqu5f\nKekN9aTTzMwK0NFR39aCiu79+3JEjIuIrYGvAd8tOH4tB+TrnQGc2IvzjwSWZqoR8f6IeKasxJmZ\nWQ+io76tBZU5pGZV4GkAJSdKWiDpDkn7dbe/mqRtJc2VtEkP1/srsF7V486UNFvSQknfzPuOAN4M\n3CDphrzvAUlrSRot6S5JZ+fHXCNpxao03J5L4SdKWlDA62NmZpB6/9aztaCi21RXlDQPGAmsC7wn\n7/8wMA7YGlgLmCXpT8A7utgPQK4+Pg3YKyL+1cO1dwMur7r/9Yh4StJQ4DpJYyPiVElfBnaOiCdq\nxBgDfCwiPiPpl8A+wM+BnwGfiYi/Sjqh9y+HmZn1qEVLnfUoq/p3c1Imd74kAZOAX0TEkoh4HLgR\n2Lab/QBvA6YBH+whQ71Q0v3A14HTq/Z/VNIcYC7wdmCLXqT//oiYl2/fBozO7a2rRMRf8/6Lunqw\npCm5dDz7J+f/oheXMzOzdmpTLa33by7VrQWsXWeIR0kl3vHAIwCSrgbWAWZHxCH5vANIGeCJpFLt\nhyVtBBwFbBsRT0s6N8fqyaKq20uAFfuS4IiYRvohUNo0hWZm7ca9f3tB0ubAUOBJ4CZgP0lDJa0N\nvAu4tZv9AM8AewDflTQZICL+I5eED6m+VkQE8A1gh3zdVYEXgWclrQPsXnX688AqvX0euRPT85K2\nz7v27+1jzcysF1xS7VKlTRVAwKciYomky4AdgflAAP8ZEY91s39zgIh4XNIHgD9IOigibunqwhHx\nsqQfAEdHxMGS5gJ/Ax4EZladOg24StIjEbFzL5/XwcDZkjpIVdTP9vJxZmbWkzYqqSoV8qw7kkZF\nxAv59jHAuhHxxe4e41VqEq9Ss4xXqVnGq9Qs41VqYNHf/1zXO23EppO6TYek3YBTSLWmP4mIEzod\nfwtwDqmZ8ingExHxUD1pqfAqNb2zRx5OswB4J/DtZifIzKxtlDCkJo/8OJ3U/LcF8DFJnTusfh84\nPyLGAlMpYG4FT1PYCxFxCXBJs9NhZtaWyqn+3Q64NyLuA5B0MbAXcGfVOVsAX863b2D5YZl1cUnV\nzMyaq86OStXDGPM2pSrqeqQ+NRUPUTVBUDafNI8CwIeAVSSt2chTcUnVzMyaq86SavUwxjodBfxI\n0oHAn4CHScMp6+ZMtSRldSj64pyppcT9UUnpfbykzkQAi0sKPXbRa6XEPWnE86XEBfjKol6PEuuT\nO1cYXkrc8+aW05kIyvtS+9n8ctL8ksrrzLdylPMh+UrRAcsZHvMwUP1HWz/vWyoiHiGXVCWNAvZp\ndC54Z6pmZtZUEaXM4zsLGJMnA3qYNMfAx6tPyBMUPRVp9omvkXoCN8RtqmZm1lwlrFITEYuBw4Gr\ngbuAX0bEQklTJe2ZT5sM3C3p76TZ+r7T6FNxSdXMzJqrpNmRIuJK4MpO+46run0pcGmR13SmamZm\nzdVGMyo5UzUzs+Zq0bVR6+FM1czMmquNSqpt31FJUmXO3iGSTpW0QNIdkmblXmFIeiDvm5f/36vq\n8ZEn6q/cP0rS8f3+RMzM2pVXqRmQ9gPeDIyNiA5J65OWh6vYOSKekLQZcA1wRd6/iLRG63cj4on+\nTbKZ2SDgkuqAtC7waB6PREQ8FBFP1zhvVaB6/2LSjB1fKj+JZmaDUBuVVAdTpvpL4IO5ivcHksZ3\nOn5DXoXmRuDYTsdOBw6QtFp3F6ieh/LmF+4pLuVmZu3MmerAk9fI24w0a0YHcJ2k91adsnNEbAls\nRZoLclTVY58DzgeO6OEa0yJiYkRM3GHUmMKfg5lZO4pYUtfWigZNpgoQEYsi4g8RcTTwP8DeNc75\nB/A4aUmgaicDBwMrl55QMzMbkAZNpippgqQ359tDgLHAP2uc90Zgo87HIuIpUhXyweWn1sxsEGmj\n6t/B1Pv3jcDZkkbk+7cCP6o6foOkJcBw4JiIeLxGjB+Q5pI0M7OitFHv37bPVCNiVP7/KuCqLs4Z\n3dPj8+3HgZUKTqKZ2eDWoqXOerR9pmpmZi3OJVUzM7OCuKRqZmZWEJdUzczMCuKSqvVkRJQT90cT\njuv5pDocPmdqKXHPGVdOegFeUzlx7xwxvJS4e8YapcQFuHOF0kKXYiCO5SvrMz0iSnojAx3lhS6W\nM1UzM7OCuPrXzMysIC6pmpmZFcQlVTMzs4K4pGpmZlaQNiqpDqhOeJJG5zVPq/cdL+mogq+zNKak\ncyXdL2m+pL9LOl/S+kVez8xsUGujCfUHVKZaBkm9Ka0fHRFbk9ZjnQtcL2mADWIwM2tRzlRbj6Qj\nJN0p6XZJF+d9K0s6R9KtkuZK2ivvP1DSdEnXA9f19hqRnAQ8BuxeyhMxMxtsIurbWlA7takeA2wU\nEYskvSHv+zpwfUQclPfdKumP+dgEYGxeJ7Wv5gCbA1c0nGozM2sbA62k2tVPkwBuBy6U9Algcd6/\nK3CMpHnADGAksGE+dm2dGSpAzXlKJE2RNFvS7Jkv3FNnaDOzQcbVv03zJLB6p31rAE8AewCnk0qg\ns3JbqYB9ImJc3jaMiLvy416sBJD0HUnzcubbG+OBuzrvjIhpETExIibuNGpM356Zmdlg5Uy1OSLi\nBeBRSe8BkLQGsBvwZ2CDiLgB+CqwGjAKuBr4giTl88d3EffrlYy3u+srOQJYly4WPDczsz6Kjvq2\nFjQQ21Q/CZwu6Yf5/jeBfwE3SFqNVDo9NSKekfQt4GTgdklDgPuBD9RxzRMlfQNYCbgZ2DkiXm30\niZiZGS1b6qzHgMtUI+JOYOcahybVOPdl4LM19p8LnNvNNY6vun1g31NpZma91qI9eesx4DJVMzNr\nMy6pmpmZFcSZqpmZWUFatNNRPZypmplZU0WH21StB29aXM6b5PFhNeedaNg5444rJe5B86aWEhfg\njAnlpHkgWlzO24JhJX3XvXXRknICA/etMLSUuJu8urjnk+owSuW9Fs8OlK94V/+amZkVxNW/ZmZm\nBXH1r5mZWUFc/WtmZlYQZ6pmZmYF8YxKZmZmBWmjkuqAWqXGzMyslTlTNTOz5uqI+rYeSNpN0t2S\n7pV0TBfnfFTSnZIWSrqo0acyaKt/JV0ObACMBE6JiGmSDiatx/oMMB9YFBGHS1ob+DGwYX74kREx\nsxnpNjNrOyWMU5U0FDgdeB/wEDBL0vS80lnlnDHA14CdIuJpSW9s9LqDuaR6UERsA0wEjpC0HvAN\nYAdgJ2DzqnNPAU6KiG2BfYCf1AooaYqk2ZJm//Gle8tNvZlZuyinpLodcG9E3JfXv74Y2KvTOZ8B\nTo+IpwEi4v8afSqDtqRKykg/lG9vAPw/4MaIeApA0q+ATfPxXYAtpKVzwa0qaVREvFAdMCKmAdMA\nfrXuAe3Tnc3MrERRZ0clSVOAKVW7puXvYYD1gAerjj0EbN8pxKY5zkxgKHB8RFxVV2KyQZmpSppM\nyih3jIiXJM0A/ga8rYuHDAF2iIhX+ieFZmaDSJ0zKlUXZOo0DBgDTAbWB/4kaauIeKbegIO1+nc1\n4OmcoW5OqvJdGXi3pNUlDSNV81ZcA3yhckfSuH5NrZlZO4uO+rbuPUyqhaxYP++r9hAwPSJei4j7\ngb+TMtm6DdZM9SpgmKS7gBOAm0kv9v8AtwIzgQeAZ/P5RwATJd0u6U7g0H5PsZlZuyqnTXUWMEbS\nRpJWAPYHpnc653JSKRVJa5Gqg+9r5KkMyurfiFgE7N55v6TZuRfwMOAy0gtORDwB7Ne/qTQzGyRK\nmPwhIhZLOhy4mtReek5ELJQ0FZgdEdPzsV1zYWkJcHREPNnIdQdlptqN4yXtQhpmcw05UzUzsxKV\ntEpNRFwJXNlp33FVtwP4ct4K4Uy1SkQc1ew0mJkNOl5P1czMrCBeT9V68tgw9XxSHRaXE5bXSop7\nxoTjej6pTp+fM7WUuD8eX06aF5cSNRk2wL6T7h0xtLTYQ0p6Le4ZUdbXZXlfw2W9FkWrd5xqK3Km\namZmzeWSqpmZWUGcqZqZmRXEHZXMzMwK0kYl1cE6o5KZmVnhXFI1M7OmijYqqTpTzSS9EBGjmp0O\nM7NBx5mqmZlZQdponKrbVDtRcqKkBZLukLRf1bGv5n3zJZ3QzHSambWNclapaQqXVF/vw8A4YGtg\nLWCWpD/lfXsB2+d1WNdoYhrNzNpHi2aQ9XBJ9fUmAb+IiCUR8ThwI7AtsAvws4h4CSAinur8QElT\nJM2WNHvmC/f0a6LNzAaqiKhra0XOVAsUEdMiYmJETNxpVEOLx5uZDR5tVP3rTPX1bgL2kzRU0trA\nu4BbgWuBT0taCcDVv2ZmBWmjTNVtqq93GbAjMB8I4D8j4jHgKknjgNmSXiUtfPtfzUummVl78DjV\nNlQZo5pXgj86b53POQFwr18zsyI5UzUzMytI+wxTdaZqZmbN5epfMzOzojhTNTMzK4irf60nr6qc\nuGMXvVZK3DtHDC8lbpl+PP64UuIeOndqKXFHj/lgKXEBrl9nw1LiXvvimqXELeddnIwoKe6ikj7T\nS8oJC8DQktJcNFf/mpmZFcUlVTMzs2K0U0nVMyqZmZkVxCVVMzNrLlf/mpmZFSPaKFMdVNW/kvaW\ntEXV/RmSJjYzTWZmg15HnVsLGlSZKrA3sEWPZ/WCJJfyzcwKEB31ba1owGeqki6XdJukhZKm5H0v\nVB3fV9K5kt4B7AmcKGmepE3yKR+RdKukv0t6Z37MSEk/k3SHpLmSds77D5Q0XdL1wHX9+0zNzNpU\nG5VU26G0dVBEPCVpRWCWpF/XOiki/iJpOvC7iLgUQBLAsIjYTtL7gf8GdgEOSw+JrSRtDlwjadMc\nagIwNiKeKvl5mZkNCq1a6qzHgC+pAkdImg/cDGwAjOnj43+T/78NGJ1vTwJ+DhARfwP+CVQy1Wu7\nylAlTZE0W9Lsm1+4p4/JMDMbnFz92yIkTSaVLHeMiK2BucBI0uLiFSN7CLMo/7+E3pXcX+zqQERM\ni4iJETFxh1F9zdvNzAYnZ6qtYzXg6Yh4KVfT7pD3Py7pbZKGAB+qOv95YJVexL0JOAAgV/tuCNxd\nXLLNzGypUH1bCxromepVwDBJdwEnkKqAAY4Bfgf8BXi06vyLgaNz56NN6NoZwBBJdwCXAAdGxKJu\nzjczszq1U0l1QHdUyhnd7l0cvrTG+TNZfkjN5KpjT5DbVCPiFeDTNR5/LnBunck1M7MaoqM1S531\nGNCZqpmZDXytWuqshzNVMzNrqmjR9tF6OFM1M7OmcknVzMysIG5TtR69oaRfXieNeL6UuHvGGqXE\nLdPikuKOHvPBUuI+cM9vS4kL8NbN9i4l7lErrVlK3NVKLJm8UtL389olveFWKnGB7peHDIzMKtpn\njfIBP6TGzMysJkm7Sbpb0r2Sjqlx/NA8x/s8SX+uXsWsXs5UzcysqaJDdW3dkTQUOJ007HIL4GM1\nMs2LImKriBgH/C/ww0afi6t/zcysqUpqU90OuDci7gOQdDGwF3Dn0utGPFd1/sosP8VtXZypmplZ\nU5XUproe8GDV/YeA7TufJOkw4MvACsB7Gr2oq3/NzKyp6q3+rV4ZLG9T+nztiNMjYhPgq8CxjT4X\nl1TNzKyp6p38ISKmAdO6OPwwaTnQivXzvq5cDJxZV0KquKRqZmZNVdKE+rOAMZI2krQCsD8wvfoE\nSdVrdO4BNLwQtkuqvSBpaEQsaXY6zMzaUUcJ0xRGxGJJhwNXA0OBcyJioaSpwOyImA4cLmkX4DXg\naeBTjV637TLV/II9FREn5/vfAf6P1Aj9UWAEcFlE/Hc+fjmpimAkcEquTkDSC8BZpEXQD5P0AWBP\n0pwD10TEUf36xMzM2lRZc/9GxJXAlZ32HVd1+4tFX7Mdq3/PAT4JkBcp3x94DBhD6mI9DthG0rvy\n+QdFxDbAROAISZUpZFYGbomIrYG7SIudvz0ixgLfrnXh6kbzG19suBbBzGxQKGOcarO0XaYaEQ8A\nT0oaD+wKzAW2rbo9B9iclMlCykjnkxY436Bq/xLg1/n2s8ArwE8lfRh4qYtrT4uIiREx8d0rj6l1\nipmZdRJR39aK2q76N/sJcCDwJlLJ9b3AdyPirOqTJE0mVe/uGBEvSZpBqgYGeKXSjprr5rfLcfYF\nDqeA8UxmZuYJ9QeCy4CpwHDg46R20G9JujAiXpC0HqlhejXg6Zyhbg7sUCuYpFHAShFxpaSZwH39\n8izMzAaBMjoqNUtbZqoR8aqkG4BncmnzGklvA/4qCeAF4BPAVcChku4C7iZVAdeyCnCFpJGASLNv\nmJlZAbxIeYvLHZR2AD5S2RcRpwCn1Dh991oxImJU1e1HSZ2czMysYK3aPlqPtuuolFchuBe4LiLc\nBdfMrMV1hOraWlHblVQj4k5g42anw8zMeqedqn/brqRqZmbWLG1XUjUzs4GlndpUnamW5JmS6gC+\nsmiVUuLeuUIpYVlcYq3OsJI+iNevs2Epcd+62d6lxAW49+7LS4n74/HH9XxSHZ4rsY5shZLeF08O\nLSfuY8PK+5AMHyCZVau2j9bDmaqZmTVVO7WpOlM1M7OmcknVzMysIAOklrpXnKmamVlTuaRqZmZW\nkHZqUx2Q41QlHS/pdYuESxotaUG+PVHSqd3EmCzpd2Wm08zMetZR59aK2rakGhGzgdllxZc0LCIW\nlxXfzGywCFxSLVQuYf5N0oWS7pJ0qaSVJD0gaa18zsS83mnF1pL+KukeSZ+pEXNpSVTSuyXNy9tc\nSZXBnqPytSrXVj5/G0k3SrpN0tWS1s37Z0g6WdJs4ItlviZmZoNFR9S3taJWKqluBhwcETMlnQN8\nvofzx5JWolkZmCvp992cexRwWI49Cngl7x8PvB14BJgJ7CTpFuA0YK+I+Lek/YDvAAflx6wQERPr\neH5mZlZDh0uqpXgwImbm2z8HJvVw/hUR8XJEPAHcQPdLs80EfijpCOANVdW2t0bEQxHRAcwDRpMy\n9y2BayXNA44F1q+KdUlXF5E0RdJsSbNvfsEL5JiZ9UagurZW1EqZaufCfACLWZbGkb04v3bgiBOA\nQ4AVgZmSNs+HFlWdtoRUchewMCLG5W2riNi16rwXu7nOtIiYGBETdxg1pqvTzMysSjt1VGqlTHVD\nSTvm2x8H/gw8AGyT9+3T6fy9JI2UtCYwGZjVVWBJm0TEHRHxvXze5l2dC9wNrF1Ji6Thkt7e1ydj\nZma945JqOe4GDpN0F7A6cCbwTeCU3DFoSafzbydV+94MfCsiHukm9pGSFki6HXgN+ENXJ0bEq8C+\nwPckzSdVC7+jzudkZmY9aKeSait1VFocEZ/otO8mYNPOJ0bE8bUCRMQDpPZQImIGMCPf/kKN05ce\nz+ccXnV7HvCuGvEnd518MzOrR6tmkPVopZKqmZnZgNYSJdXqEqaZmQ0urdo+Wo+WyFTNzGzw6mif\nPNWZqpmZNVc7Tf7gTLUkK5Q0hdadKwwvJ3BJhrXoVGLdufbFNUuJe9RK5cQF+PH440qJe+jcqaXE\nPauk9AIc+fgNpcQ9aZ2dS4k7cgB+RorWTi+BM1UzM2uqdur960zVzMyaqkOu/jUzMyuEq3/NzMwK\n4upfMzOzgnhIjZmZWUHaaUhNW01TKOkISXdJurCL4wdK+lEXx17I/4+WtCDfnizpWUlzJd0t6U+S\nPlDeMzAzG3yizq0VtVtJ9fPALhHxUIExb4qIDwBIGgdcLunliLiuwGuYmQ1arv5tQZJ+DGwM/EHS\nucA78/2XgCkRcXun8zcCLgJGAVf05hoRMU/SVOBwwJmqmVkB2qmjUttU/0bEocAjwM7AaGBuRIwF\n/gs4v8ZDTgHOjIitgEf7cKk5dLHIuaQpkmZLmj3zhXv6knwzs0Grnap/2yZT7WQScAFARFwPrClp\n1U7n7AT8It++oA+xu6yoiIhpETExIibuNGpMX9JrZjZodai+rRW1TfVvner5sTMeuKvohJiZDVau\n/m19NwEHQOrBCzwREc91OmcmsH++fUBvgkoaC3wDOL2YZJqZWUedWytq10z1eGAbSbcDJwCfqnHO\nF4HDJN0BrNdNrHdWhtSQMtMj3PPXzKz1SdotD4e8V9IxNY6PkHRJPn6LpNGNXrOtqn8jYnTV3b1r\nHD8XODffvh/YserwsXn/A8CW+fYMYLUSkmpmZlmU0D4qaSipIPQ+4CFglqTpEXFn1WkHA09HxFsl\n7Q98D9ivkeu2a0nVzMwGiJKqf7cD7o2I+yLiVeBiYK9O5+wFnJdvXwq8V2psyRxnqmZm1lQlZarr\nAQ9W3X+I1zf1LT0nIhYDzwJr1vs8wJmqmZk1Wb3jVKvnBsjblGakv1pbtam2kgMmPNjzSXU4b+4G\npcQt89fVWxctKSXuvSOGlhL3tVKiJquV1GXxuZL+gGeNP66cwMBn504tJW6UlOYpV326lLjx1COl\nxAVgldXLi12gesecRsQ0YFoXhx8Gqr8w18/7ap3zkKRhpD40T9aXmsQlVStVWRnqQFRWhjoQlZWh\n2sBUUvXvLGCMpI0krUAaQjm90znTWTY6ZF/g+ohoaLIml1TNzKypyvi9GRGLJR0OXA0MBc6JiIV5\n/vbZETEd+ClwgaR7gadYNndB3ZypmplZU5U1j29EXAlc2WnfcVW3XwE+UuQ1namamVlTteo8vvVw\npmpmZk3VTt0NnKmamVlTteoybvVw719A0pWS3tDsdJiZDUYdRF1bK2rLkqqkYXl2jJ7OE6CIeH8/\nJMvMzGpop+rfli6pSlpZ0u8lzZe0QNJ+kh6QtFY+PlHSjHz7eEkXSJpJ6iJ9oKQrJM2QdI+k/87n\njc6rFpwPLAA2qMSsdb38mG0k3SjpNklXS1q3Oa+ImVn7qXdGpVbU6iXV3YBHImIPAEmrkVYR6MoW\nwKSIeFnSgaQJlbcEXiKtUPB74AlgDPCpiLg5x+3yepKGA6cBe0XEv3NG+x3goEKfqZnZIOWSav+5\nA3ifpO9JemdEPNvD+dMj4uWq+9dGxJN532+ASXn/PysZai+utxkpY75W0jzSEnHr17p49TyU5z3w\naB+eppnZ4NWh+rZW1NIl1Yj4u6QJwPuBb0u6DljMsh8DIzs95MXOIbq43/m87q53GbAwInas9ZhO\nj186D+VTe727VWsnzMysJC1dUpX0ZuCliPg5cCIwAXgA2Cafsk8PId4naQ1JK5IWLZ9Zx/XuBtaW\ntGM+Z7ikt9f5lMzMrBP3/u0/WwEnSuogLR7yOWBF4KeSvgXM6OHxtwK/JlXX/jwiZksa3ZfrRcSr\nkvYFTs1tusOAk4GFdT8rMzNbqjWzx/q0dKYaEVeTJkPubNMa5x5f47yHImLvTuc9QGojrd43Ot+s\neb2ImAe8qzdpNjOzvmmnjkotnamamVn7a9Wq3Hq0baYaEecC5zY5GWZm1oP2yVLbOFM1M7OBwdW/\nZmZmBXH1r/XowjkblBJ3oP3B7lthaGmxh5T0ORxRTlheKXGw+golvRZHPn5DKXFj/HE9n1SnQ+dO\nLSXuj0tKc5mTGJT1GfnCgx8oNF77ZKkD7zvazMzajKt/zczMChJtVFZ1pmpmZk3lkqqZmVlB3FHJ\nzMysIO2TpTpTNTOzJmunkmpLr1LTnyQtkTSvahstabKkkHRI1Xnj8r6jmpleM7N20VHn1opcUl3m\n5YgYV70jr2izAPgo8JO8+2PA/H5NmZlZG2un3r8uqfbsn8BISetIErAb8Icmp8nMzFqQM9VlVqyq\n+r2s07FLgY8A7wDmAItqBZA0RdJsSbNnvnBPyck1M2sPrv5tT6+r/q3yS+ASYHPgF6TM9XUiYhow\nDeC0DT7RPvUZZmYlcvXvIBMRjwGvAe8DrmtycszM2opLqoPTccAbI2JJalo1M7MidET7lFSdqfZS\nRPyl2WkwM2tH7ZOlOlNdKiJG1dg3A5hRY//x5afIzGxwaKfJH5ypmplZU7VTRyVnqmZm1lSt2umo\nHs5UzcysqVz9az36+LgHS4n7s/kblBJ3REnv6U1eXVxOYOCeEeW8fReV1Ll77fJeCp4cWk7ck9bZ\nuZS4U676dClxAX48/rhS4h46d2opcRffMr2UuACsvGp5sQvk6l8zM7OCuPrXzMysIOFxqmZmZsVw\nm6qZmVlBXP1rZmZWEHdUMjMzK0g7Vf+23So1kkZLWtDsdJiZ2eDTdplqvSS51G5m1gQRUdfWCElr\nSLpW0j35/9VrnPMWSXMkzZO0UNKhPcVt60xV0saS5kraXtKJkmZJul3SZ/PxyZJukjQduDPvu1zS\nbfkFnJL3DZV0rqQFku6Q9KUmPi0zs7bSpPVUjwGui4gxpHWyj6lxzqPAjhExDtgeOEbSm7sL2ral\nM0mbARcDB5JejGcjYltJI4CZkq7Jp04AtoyI+/P9gyLiKUkrArMk/RoYDawXEVvm2G/ox6diZtbW\nmtRRaS9gcr59HmlFsq9WnxARr1bdHUEvCqLtWlJdG7gCOCAi5gO7Ap+UNA+4BVgTGJPPvbUqQwU4\nQtJ84GZgg3zefcDGkk6TtBsv/QHQAAAgAElEQVTwXK2LSpoiabak2ef989FSnpiZWbvpIOraqr9z\n8zalD5ddJyIqX9SPAevUOknSBpJuBx4EvhcRj3QXtF1Lqs8C/wImkap1BXwhIq6uPknSZODFTvd3\nIRX3X5I0AxgZEU9L2hr4D+BQ4KPAQZ0vGhHTgGkAT37w3e3Tnc3MrET1to9Wf+fWIumPwJtqHPp6\npzghqWYiIuJBYGyu9r1c0qUR8XhX12zXTPVV4EPA1ZJeAK4GPifp+oh4TdKmwMM1Hrca8HTOUDcH\ndgCQtBbwakT8WtLdwM/752mYmbW/sobURMQuXR2T9LikdSPiUUnrAv/XQ6xH8siSdwKXdnVeu1b/\nEhEvAh8AvkQq2t8JzMkvylnU/kFxFTBM0l3ACaQqYID1gBm5+vjnwNdKTr6Z2aARdf5r0HTgU/n2\np0hNhsuRtH7uX0PuHTwJuLu7oG1XUo2IB4At8+1ngG3zoenAf3U6fUbeKo9dBOzeRegJBSbTzMyy\njuZMqH8C8EtJBwP/JDXrIWkicGhEHAK8DfhBrhoW8P2IuKO7oG2XqZqZ2cDSjCw1Ip4E3ltj/2zg\nkHz7WmBsX+I6UzUzs6Zqp2kKnamamVlTOVM1MzMriBcptx4NXamcjtUv1R5K1bARoVLijtKSUuIm\n5bx9y0rxSh3lfXE8Nqycv9/IkpIcT3U7fr4hHeW8FCy+ZXopcYdtv2cpcQEWz/pdabGL5JKqmZlZ\nQbyeqpmZWUFc/WtmZlaQdqr+bdsZlczMzPqbS6pmZtZU7VT9221JNS95c7+kNfL91fP90ZLGSPqd\npH/kRb1vkPSufN6Bkv5dtVr6pZJWyseOl/RwPnanpI+V/zTNzKxV1bv0WyvqNlPNS96cSZojkfz/\nNNIE9b8HpkXEJhGxDfAFYOOqh18SEeMi4u2kVWP2qzp2Ul5JfS/gLEnDG30ikvqt1N2f1zIza3dN\nmlC/FL1pUz0J2EHSkaQZ+r8PHAD8NSKWDtyKiAURcW7nB+cMaGXg6c7HIuIe4CVg9XzuJpKuyiXf\nm/Lya5X9N0u6Q9K383JuSJqcz5tOWoUGSZ+QdGsuCZ8laWjezpW0IMf4Uj73iFxavl3SxXnfGpIu\nz/tuljQ27z9e0gWSZgIX9OrVNTOzHnVE1LW1oh5LXHn90aNJy6Ltmu+/HZjTw0P3kzQJWBf4O/Db\nzidImgDcExGVdeymkVYHuEfS9sAZwHuAU4BTIuIXkg7tFGYCsGVE3C/pbaQS8U45nWeQfgAsBNaL\niC3zdd+QH3sMsFFELKra901gbkTsLek9wPnAuHxsC2BSRLzcw3M3M7NeatVSZz162/t3d+BR8pJq\nnUm6LJcCf1O1+5Jcxfsm4A7g6KpjX5K0ELgF+E6OMQp4B/CrvG7pWaQMGWBH4Ff59kWdLn9rRNyf\nb78X2AaYlWO8l1QlfR+wsaTTJO0GPJfPvx24UNIngMV53yRySTQirgfWlLRqPja9uwxV0hRJsyXN\nPvcf5c0YY2bWTtqppNpjpippHPA+YAdSZrguqeS3dH3RiPgQcCCwRufHR+rW9VvgXVW7T8ptrfsA\nP5U0MqflmdwOW9ne1ovn8GJ1coHzqh6/WUQcHxFPA1uT1k49FPhJPn8P4PT8XGb1oq30xe4ORsS0\niJgYERMP3OTNvUi6mZkNmjZVSSJ1VDoyIv4FnEhqU70I2ElS9aSVK3UTahLwj847c5vsbOBTEfEc\ncL+kj1SuLWnrfOrNpAwYYP9urnMdsK+kN+YYa0h6i6S1gCER8WvgWGCCpCHABhFxA/BVYDVgFHAT\nqcoYSZOBJ3LazMysBO1UUu2pZPYZ4F95oVZIbZyfBrYDPgD8UNLJwOPA88C3qx5baVMdAjxEKsnW\nMhW4SNLZpMzsTEnHAsOBi4H5wJHAzyV9ndS2+2ytQBFxZ37sNTnTfA04DHgZ+FneB/A1YGiOuRqp\nhHtqRDwj6XjgHEm3kzpRfaqH18jMzBrQqqXOenSbqUbENFLnocr9JVRV+wLv7+Jx5wLndnHs+E73\nbwM2y3fvB3ar8bCHgR0iIiTtXzk/ImaQqnSr410CXFIjxoQa+ybVSN9TwN49pdvMzIrRqqXOegyU\n8ZbbAD/K1dHPAAc1OT1mZlaQQVNSbRURcROpo5GZmbWZiI5mJ6EwAyJTNTOz9tWqUw7Ww5mqmZk1\nVTtNqO9MtSSLnymnOmPlUClxO8oJy7MlvsWGlPQ5HFrSa/HykJICA8MH2nfSKquXFrqs9wUrr9rz\nOXVYPOt3pcQFGLbtB0qLXSSXVM3MzArikqqZmVlB2mlITW/n/jUzM7MeuKRqZmZN5XGqZmZmBXGb\nqpmZWUHaqfdvn9tUJW0g6X5Ja+T7q+f7oyWNkfQ7Sf+QdJukGyS9K593oKR/S5onaaGkSyWtVBX3\nk3lN1jskzZV0VN5/rqR9i3iykt4s6dKq+7+QdLukL0maKmmXIq5jZma9FxF1ba2ozyXViHhQ0pnA\nCcCU/P804DHSot9H5SXdkLQlMBH4U374JRFxeD52EbAfafWY3Ukr0ewaEY9IGgF8sqFnVjvtjwD7\n5uu/Cdg2It5aTyxJwyJicc9nmplZd9z7F04CdpB0JGmll++Tlm37ayVDBYiIBXnFmuXkxcBXBp7O\nu75GyowfyY9bFBFn13jccZJm5RLttDzBPpKOkHRnLnVenPe9O5eK5+WS7yq5NL0gh7sGWC8ff2d1\niVjSNpJuzKXtq/PC7EiaIelkSbOBL9b52pmZWZV2KqnWlalGxGvA0aTM9ch8/+3AnB4eup+keaSl\n3NYAfpv3bwnc1otL/ygito2ILYEVSWu6AhwDjI+IscChed9RwGERMQ54J2lN1Wp7Av+IiHF5wn4A\nJA0HTgP2jYhtgHOA71Q9boWImBgRP+icOElTJM2WNPv8hx7txdMxM7MOoq6tFTUyTnV34FFShvg6\nki7LJcrfVO2+JGdybwLuIGXMfbGzpFsk3QG8h5SRQ6p2vlDSJ4BKlexM0iLqRwBv6ENV7Wak53Rt\n/gFwLLB+9XPo6oERMS1nuBM/uf66vX9WZmaD2KAvqUoaB7wP2AH4Uq4eXUjVQuAR8SHgQFKJdDmR\nXo3fAu/KuxaS1kzt7pojgTNIJcitgLOBkfnwHsDp+fqzcnvnCcAhpBLtTEmb9/bpAQtzCXZcRGwV\nEbtWHX+xl3HMzKwXOiLq2lpRPb1/BZxJqvb9F3AiqU31ImAnSXtWnb5SjRAVk4B/5NvfBU7MnYeQ\ntIKkQzqdX8lAn5A0imUdjoYAG0TEDcBXgdWAUZI2iYg7IuJ7wCygt5nq3cDaknbM8YdLensPjzEz\nszpFnf9aUT3jVD8D/Csirs33zwA+DWxHauP8oaSTgceB54FvVz12P0mTSJn5Q6SSLBFxpaR1gD/m\nTDtIbZlLRcQzks4GFpB6Gs/Kh4YCP5e0GqmUeWo+91uSdgY6SCXhPwA91slGxKu5w9KpOeYw4OQc\nw8zMCtaqpc56qFXrpQe6J/7j3aW8sOfdtUEZYUubBWTjV5eUFBkeGD60lLgvlzQj9htLHID1RDkv\nBSNL+no45Lf7lxMYOPuDF5cS95AL3lNKXF5+oZy4lLf02/C1Ni50HcORIzes6532yiv/Km89xTp5\nRiUzM2uqVq3KrYczVTMza6p2qjF1pmpmZk3lTNXMzKwg7ZOlUv+gW2/FbcCUgRR3IKbZr4VfC78W\nzXstBtNWUj9H66MpAyxumbEHWtwyYw+0uGXGHmhxy4w90OIOKs5UzczMCuJM1czMrCDOVFvDtAEW\nt8zYAy1umbEHWtwyYw+0uGXGHmhxBxXPqGRmZlYQl1TNzMwK4kzVzMysIM5UzczMCuJM1VqGpO7W\n320JkoZKuqHZ6eiLnOYvNTsd1nf5b3dhibH9viiYpylsEkl38PrZuZ4FZgPfjogn+xjvuG4OR0R8\nq49J7Bx/GLA7yxZ7vwu4KiIaXtBM0juAnwCjgA0lbQ18NiI+32Dc/wH+NyKeyfdXB74SEcfWGzMi\nlkjqkLRaRDzbSPo6k/S/pPWHXwauAsYCX4qInzcSN6f5Y8BJjadymbxe8ReAzfKuu4AfRcSMguKv\nA/wP8OaI2F3SFsCOEfHTOuN9ubvjEfHDeuJ2usYXgZ+R1pL+CTAeOCYirqknXv7bvUXSChHxaqPp\nqxG78PfFYOfev02Sv0CXABflXfsDK5EWYJ8UER/sY7yv1Ni9EnAIsGZEjGogresB1wOPAnNJi8GP\nB94E7BwRj9QbO8e/BdgXmB4R4/O+BRGxZYNx51biVe2bExETGox7Ben5Xwu8WNkfEUc0GHdeRIyT\n9CHgA8CXgT9FxNaNxM2xTwKGA5ewfJrn1BlvD+BHwFRgDuk9MQE4Fjg8Iq4sIM1/IGVQX4+IrfMP\nu7kRsVWd8TqAecAfgEU5zUtFxDcbTDKS5ue0/gfwWeAbwAWNvOcknQ+8DZjO8n+7In4EFPq+MJdU\nm2mXTh+0Oypf+JI+0ddgEfGDym1JqwBfBA4CLgZ+0NXjeuk7wJkRcXL1TklHAN8FPtVgfCLiQWm5\n77giVjcfKmlERCwCkLQiMKKAuL/JW9GG5//3AH4VEc92ek0aMS7/P7VqXwD1rrx9NLB3RMyv2jdP\n0mzgNKDhTBVYKyJ+KelrABGxWFIj74vxwMdIr+9twC+A66LYkkXlD/Z+Uma6UI3/Ef+RtyHAKg3G\n6qzo98Wg50y1eYZK2i4ibgWQtC0wNB+rq0pV0hqk0s0BwHnAhIh4uoC07hARB3beGRGnSrq7gPgP\n5irgkDSc9IPgrgLiXghcJ+ln+f6nSa9LQyLiPEkrAJvmXXdHxGuNxgWmS/obqfr3c5LWBl4pIC4R\nsXMRcaq8qVOGWrnO7bnatggvSlqT3EwiaQdSE0ldcnrnA8fk99vHgNMkfTUipheRYOA2SdcAGwFf\nyz9wOxoJWClBSxqV77/QcCqXxS76fTHoOVNtnkOAc/IHRcBzwCGSViaV/vpE0onAh0mzomxV5AeP\n9CXflZcKiH8ocAqwHvAwcA1wWKNBI+J7kuYDu+Rd34qIqxuNK2kyKXN+gPS320DSpyLiTw3EHAL8\nFjgReDa3d70E7NVoenP8Qtsnqaoq7OOxvvgyqcpzE0kzgbVJzQQNyT9WxgNbAQ8B/9dozCoHk0p/\n90XES/lHwacbCShpS+ACYI18/wngkxGxsNHElvC+GPTcptpkklYDaLTTS24vWkQq5Vb/UZXCx6oN\nxL4POKrWIVJHoE3qjV22/KWxHek1uTUiGv4ClXQb8PGIuDvf3xT4RURs02Dc17UBF6WE9slngFo/\nIkTqE7B6/ald7jrDSB2hRIM1ApIOAj4KjAQuBX5ZxPuhxnVWB8bk6wDQ4A+uv5D+bjfk+5OB/4mI\ndzSY1MLfF+ZMtWkkjQD2AUZTVWMQEVO7ekyzVFWf1hQRjf4SP7XG7meB2RFxRQNxP0oq+c0gfSm/\nEzg6Ii6tN2aOe3tEjO1pXx1xvw/8FfhNwe18SJoVEdtWZ9yVjlF1xnt3d8cj4sZ64na6xkdIPcyf\nl3QsqSPUtxvoXNUBLAD+WUlm9fGI2LOR9OZrHEJqvlif1ClqB+CvEVF3G2Wl81NP++qMXej7wlz9\n20xXkDKO20glzEIpjfncAnggIp5oJFajmWYvjCQN1flVvr8PcD+wtaSdI+LIOuN+Hdi2UhrJ1X5/\nJJVSGjFb0k+AylCXA0hDoRr1WVKV52JJr1BALUOVotsnG840e+EbEfErSZOA9wLfB84Etq8zXn+0\nH34R2Ba4OSJ2lrQ5qXq1EfdJ+gapChjgE8B9DcasKPR9Yc5Um2n9iNitqGCS9gROBZ4iDWs4HXgc\nGJ07YtTdQacfxveNBXaKiCX5emcCNwGTgDsaiDukU/XekxQz4cnnSG2+lSE0NwFnNBo0Ioru2Vmt\n0PZJ1R5nvVSjpfas0tN3D+DsiPi9pG83EO/+iPhXAenqzisR8Yokcs/zv0narOeHdesg4Jss63H+\np7yvCKW0Ww9mzlSb5y+StoqIRjKNat8CdgVWA24AxkbEfZLeCFxHY71ey/yyB1idNPFD5RfyysAa\nubNOI6X4qyRdTRo6AbAfBQz1yEN0fpi3QhXdHlcVY06usi2kfZI0jrZsD0s6C3gf8L3cZNLIj6LL\nSVXISPp1ROxTQBo7e0jSG/K1rpX0NMuqm+uSe/AfAWkWJGDliHiu4ZRSyvti0HObapNIuhN4K6ma\nszIQPer9hd+pTeSO6o4GZXaAKYKkg0ml6xmk1+FdpCqzXwDHR8TRDcTeB9gp370pIi5rLLUgaSfg\neOAtLN8evnGDcQtvj+sU/x28vg3//CJilyE3YewG3BER90hal9Szva7ZiTp9Rkr/TOTMajVSu3Dd\nsyFJuojUQ34JMAtYFTglIk5sIOZ7IuJ6SR+udTwiyhiHPSi4pNo8uxccb0gu5QwBOvLtyqDzwud4\nVgEzE1VExE9zL8T/Rxqfeg3wUES8SJpkoJHYvwZ+3Xgql/NT4Euk9vAiJqmoKKM9DgBJFwCbkDLr\nSpoDqCtTlfQ83Vf/NtLbfNVcEhtJ+qFVGYO9iMbarqOL24XIpciFEbE5FNruvEVEPCfpANJsUMeQ\n3nt1Z6qkH67XA7VmbgvKmdxkUHCm2s+qvjCeLzj0aqQPWiUjre4hWUZ1RGFT/XRVQqPOWV26+cIv\nquPPsxHxhwZj1FJGe1zFRNKXcyHvhUr7r6RvkaavvID0+h4ArNtg+ItI1cu3kf6O1e+1AOqtEdha\n0nM53or5NhT0vsjNFXdL2rDgttvhSpOi7E2aW/k1SY3+HSuTwvw0Iv7cYCyr4ky1/5XyhRERoxtO\nWd/8vsBYhZbQyurwI6lSMr9BabKN31DVc7veoR5VCm+Pq7KANFfzowXFq9iz09COM5Um3OhugYdu\nRcQHJAl4d5GZU0QM7fmshq0OLJR0K8vPpdvIcJ2zSBONzAf+JOktpMliGvFp0oQrp5Lbma0YblNt\nE/mD9kxlEgmlFUT2Jn0YT2+kTSfHGwr8MUqY1qxqrNw8YPuIWCRpYUS8vehrNULdL/kWRbV95msV\n1R73W9KPtVVIM/3cyvI/BBoam5knJjidNMd0kKb+O6ygiQmW6xswEHQ1frfoIUiShkUDK0RJ+gWp\n9uLNpHmFlx6igb4d5pJq00i6LiLe29O+Pvgl8CHgWUnjSGM+v0v6Ij2DNC1i3aLEJc8ot4RWmMoP\nCkkbR8Ry4wQlNdRJqSrOJGBMRPwsj6tdj9SZrV7fLyJd3fg4qcRzCilTnZn3FWGOpG0jYlZB8UoX\nETfmH7hjIuKPubNVQyVkdbGcHKnvQb3p/JikNwFXAw1PemHLuKTazySNJC3JdgMwmWXVv6uSSiWb\nd/HQnuIundFHaWaejoj4T6U5ZecV8ctTJS151ukahZTQylSrk5ak26LxaQr/m1R62CwiNpX0ZtJq\nNTv18NDexF4ZeDkiOpSmVdwc+EMrD59QWlzgraQfWC8yAEpRkj4DTCENCdtE0hjgxw38WC5lOTkr\nj0uq/e+zwJGkapfqjkXPkdanrFd12+x7gMpyWR0qbvmwspY8W6roarIi5bbetwOrdRqKsCpV40ob\n8CHSj5Y5ABHxiNIqJ0X4E/DO3Cv8GtLQjP1IHYv6TNJpdN/7t4gfWv9RQIz+dhhprulbAPJQoDc2\nGLPw5eQk/TIiPqrXT+LR8j9cWp0z1X4WEacAp0j6QkScVmDo6yX9ktQRZXVSd3ny2L5CSnyRljxb\nEdgw8mTyg8xmpE5mb2D5oQjPA58pIP6rERGVnp25dFkURVo15WDgjIj439yhqF5FTMvYrYj4Z+4c\nNolctVxAZ7CyLYqIVyt5ntIE9Y1WBxa+nBypcyD0zyQeg4qrf5tIaUmnLVh+9px6xw2KVPJYl7T6\nxsN5/3jgjVHMkmcfJLXRrRARG+W226mNdnYZaCTtGBF/LSHuUaTZlN5Hag8/CLioiB9fkuYCnwdO\nAg7OpZ3COgKphLU+JR0HfIRltSN7k6rDG5mqsFSS/hd4Bvgk8AXSa74wIo5tIOYQli0n94zSXL3r\nRcTtBaR3wDULtDpnqk2S288mkzLVK0mTQfw5Ilp23k2lJc/eA8yomplmQURs2dyU9S+lVXte98GJ\niIbmY5V0BKmmYTtSNdzVEXFtIzGrYr8b+AqptPe93LHqyEarabX8Wp8C/k1xa33eDWwdEa/k+yuS\n+gcUNXa3cJK2JWWAu5L/hsCjEfG7BmJWxv9uHBFTJW1IWiT+1gLSextp9abVSZ3MZpFqTOpqFrAS\nZtqxXtuXtPLGY5FWgdma1EGnLpKel/Rcje15LRvk3qjXavT8bbQaaiD6HWmc7u9J8yqvChRRQnsj\nqYT6FtJqOn8sICaQ2qojYs+I+F6+f19B7Z7TgC9HxFsiYkNSxn12AXEBHmH5tuoRpEXsW9lZpPHW\nH8k/kF8gdSxqxBnAjqThSpCaG05vMGaFIuIl4MOkZoGPkPoNWJ3cpto8lSqXxZJWBf4P2KDeYGVN\neNDJQkkfB4bmXo1HAH/ph+u2lEhTHy6Vx/w1PCtNRByrtMTXrqTB+T/K7eQ/jYh/dP/o2iSdHBFH\nVo1X7XzNRqvuV468eHaON6PAtuBnSe+5a0lpfx9wq/L6u0X2Oi/QvsClkj5Gmgrwk6S/ZyO2j4gJ\nuQqfiHha0goNxqyQpB1JJeGD877+mCSjbTlTbZ7ZeWzm2aRewC+QpuZrZV8grVG6iDTZ/dWk1XEG\nuzGkUmbDckelx4DHgMWkarlLJV0bEf9ZR8jKGpxljVctc63Py/JWMaOguKWJtDLU/qQx1/8Cdo2I\nlxsM+5rS5CuVDmxrU1wN0ZGkkQKX5Xb2jUnD/axOblNtAZJGA6sW0fGgv6jgJagGEi0/t3CQ1q09\nJhpc2SMP8v8k8ARpkP/lkeZ5HQLcExGbNBK/SJIuiIj/p7TW7mhSD11IQ3e+GWm5skbiDwXOHyht\nezWGpryRVNJeBI2tL6s0kf5+pOkEzyOVho+NiF/VneDa1xkCjBqMn+kiuaTaAiLiAUmbSjo7IooY\nmlEK1ViCSlJDS1ANRBGxitKqKdXrnhbx63QN4MMRsdxsUrmZoK6hDzW+7JceorHxiNvkySk+Bexc\niVcVuyGRZvB6i6QVWnUSkE5KG5oSERfmDkXvJb22e0fEXUXE9me6eC6p9jNJY0lVcW8mVRGdTpr0\nYXvgBxFxUhOT1y1J8yJiXP7lPIG8BNVgGyiuktc9LZLSlHld6pyB9yHuEcDnSAtAVHceqmTWDU/b\nKOl84G3AdJafwavwxeFblTotJ1dCfH+mC+bev/3vbNJKNfuQhh/MI01o/dZWzlCz6iWopuexbIPx\nV1llVZ1/RpoPeDxpbGLLiYh/VjZSVeTWwFjSJAV1z68cEadGxNuAcyJi46ptoyIy1OwfpJ7WQ0gL\nAlS2QSMilgB352E0ZfBnumCu/u1/IyLi3Hz7bklfrLMDSjP8mDS5++0UtwTVQFTmuqelyKXr40gz\nbQk4TdLUiDinkbgR8bki0tdF7G+WFXuAKWM5uYoylpUb1Fz928+UJgn/GMvanS4kreohKGRNzsLl\nzihL75J+yf6bNIzkwWhgCaqBSNJlpCEvR5Imw3gaGB4R729qwrqRJ1J4R0Q8me+vCfylxSdSuIHa\nw4Barpq9TOqn5eSqrtfQsnKDnTPVfqZ+XJOzKHn2p87WIE14fnxEXNzPSWoZGgCr6sDSdU8nV9KY\nxznOiALWPS2LpOpVf0aSmkwWD6CanQFB0h6kCR+qp0ud2rwUDWzOVK1uuQfsH8NLULWsqlqGccBW\nwBWk0t9ewO0RcWCTklYXSbdGxHbNTkd/6jSEq+JZ0qIGX4lOa/v2MfaPSUtR7kwaxrUvcGtEHNzt\nA61LblNtAZKmRcSUZqejryLiqTwvqbWuSseef+St4oompKVP8o+2iiGktWbrnspzADsZeIjUwVHA\n/sAmpCUCzyHNIV6vd0TEWKX1mL8p6QfAHxpM76DmTLU1TGx2AuohaWdSe6K1qAHe2ec2UglNwGuk\nDjWDsQS1Z0RsXXV/Wh4K81VJ/9Vg7MpsTy/lccdPkla6sjo5U20N/9fsBHSniwkE1iBNeP7J/k+R\n9dUA7fTzVVJb9XN5KsQJwEtNTlMzvCTpo8Cl+f6+wCv5dqPtd7/L06WeSCr5Bqka2OrkNtUmkbRR\nRNzfad+2ETGrWWnqSo0JBAJ4MiJerHW+tZ6B2OknV0mOlTSJNMf094HjImL7JietX+X5eE8hrVQT\nwM3Al0iTbmwTEQ0v5pCvMwIYGa9ficr6wJlqk0iaA3wwli0m/m7gR1HQotFmPWn1Tj+S5kbEeEnf\nBe6IiIsq+5qdtoFO0oe7O97oPNaDmat/m+ezwOWSPkiq1vou0LLjHG1gG6Cdfh6WdBZpybfv5ZLU\noJsFTtKmwJnAOhGxZZ7qdM+I+HYDYT/YzbEAnKnWySXVJsrrGJ5Fah/ZIyL+3eQkWZuSdD/L2t8W\nkzr9TC2q6rAMklYCdiOVUu+RtC6wVURc0+Sk9StJNwJHA2dVSumSFkTEls1NmdXikmo/q7FY9Eqk\nMWc/lVTU1GNmnW0BfJ60RFsAN5HGObasiHiJqhJTRDwKPNq8FDXNShFxa6fRaw3NeJTHLz8bET/t\ntP9gYJWIOLmR+IOZM9X+V9Zi0WbdOY80p+up+f7HSQuLf6RpKbLeekLSJixbpHxfGv9xcQBpdaXO\nLiD92HKmWidnqv2ser5OSeuQVjuBNItJSw+tsQFty4jYour+DZLubFpqrC8OA6YBm0t6mLSoxSca\njDksr0iznIh41RO6NGbQNfq3ijzu7FZSSeGjwC35F6hZGeZIWloykbQ9LV79a0lE3BcRuwBrA5tH\nxKSIeKDBsEPyj/rl1NpnfeOOSk0iaT7/v737CZmqisM4/n3KwghNwSBIIirRVVmWhJgLITByERFU\nG61FSwuUCGoRZVFgWkHJPm0AAARASURBVIREUZvcBCG1MKhNIgoVRWUkWClBIW76t7IotKfFudem\nN9+3nDsz977e5wMDc+5lzpzFwG/O+Z17fnBrPTuVdCnlHN3rZv5kxNmTdBhYCnxfXboC+JqSm3OK\nUndTVaR8oe0fq/aFwEZgc1XPdth+NwAPAlsohz4ArKAcArHT9uuNBt5jWf5tz3lTlnt/IisHMT7r\n2h5AnB1J91CeDjgh6QjwNOWs308oOdGh2d4l6QfgSaDeRXyIcrhGzv5tIDPVlkjaBlwLvFFduptS\nNeSR9kYVEV0h6RBwh+2jkm4APgTusr2n5aHFDBJUW1SdarK6ah6w/Xab44mI7pD02WBZxVE+mypp\nLuWP/M/AO5TnYNdQKhltrZeb4+wlqLao2hSwkrJVPrt/I+I0SceAHQOXNg+2be/414f+f99vUir/\nXAwspCz97qH8yV9ue/2wffddgmpLqt2/24B9lNJWtwAP29490+cioh8kPT7T/SZl/epZr6Q5wDHb\nlw3c+yIbJoeXjUrteQy4aeruX/4u7xQRPTbmWrh/VN9xUtLxKfdOjfF7z3kJqu3J7t+ImNZA3vMX\nytLsKPOeiyW9SFklq99TtS9v0G/vZfm3Jdn9GxEzGWfeU9LGme7nOdXhJai2KLt/I2I6yXvOTln+\nbVFVCPgtSYsoy78REbWx5T0lrQausr2rau8G6pq7T9ne26T/PktQnbDq/NVnKc+HbaVUhVhEOYtz\ng+332hxfRHTGOPOeTwCbBtpLgfsoS82PAgmqQ0pQnbydlB/tJZQf7m22P5K0jJJfTVCNCCgbk2pT\nix80LYYw3/ZglaIjtj8FkPRMw757LTnVCZN00Pby6v3hwUOxJX1u+/r2RhcRfSDpiO0l09w7avua\nSY/pXJFHOCbvz4H3v025l384EQGUvGdVTaZu75a0t3qtbdj9V5JuP8N3rqdUL4ohZaY6YZJOASco\neZGLgF/rW8Bc2xe0NbaI6A5J7wOb6mVaSV8ykPe0PXTlIUlLKGf+fsA/S7+tAtbb/qbB0HstM9UJ\ns32+7fm259meU72v2wmoEVE7Y97T9n5gXsO+f6c8J38AuLJ67a+upVB5A9moFBHRTQsGG7bvHGg2\nDXz7gJeB7bZPwekCH68By4AbG/bfW5mpRkR00zjzniuAq4GDktZKegj4mFKzdWXDvnstOdWIiA6a\nRN6zCqbPA8eBm20fa9pn32WmGhHRTWPLe0paIOkV4H5gHaU61rsj2FXce5mpRkR0kKRvOXPeczuw\nzPbQec+q75eAF2yfrK4tr659Z/vepuPvq8xUIyK6aZx5zzW2n6sDKoDtg7ZXkSMKG8lMNSKiw5L3\nnF0yU42I6KDkPWenzFQjIjooec/ZKUE1IqKDJC2ebqlX0gO2X530mOK/JahGRESMSHKqERERI5Kg\nGhERMSIJqhERESOSoBoRETEiCaoREREj8hei3gQzalF6SQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=[7,5])\n",
    "sns.heatmap(train_meta.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_importance(m, feature_list=['User-ID', 'ISBN', 'loc', 'age', 'author', 'publisher', 'years']):\n",
    "    try:\n",
    "        df = train.copy()\n",
    "        df_plot = pd.DataFrame({'features': feature_list, 'importances': m.feature_importances_})\n",
    "        df_plot = df_plot.sort_values('importances', ascending=False)\n",
    "\n",
    "        plt.figure(figsize=[11,5])\n",
    "        sns.barplot(x = df_plot.importances, y = df_plot.features)\n",
    "        plt.title('Importances of Features Plot')\n",
    "        plt.show()\n",
    "    except KeyboardInterrupt:\n",
    "        print ('KeyboardInterrupt')\n",
    "    except:\n",
    "        print ('no feature importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor\n",
      "1.2264433017424923\n",
      "XGBClassifier\n",
      "1.266796565745075\n",
      "surprise\n",
      "1.2186493570379935\n",
      "keras\n",
      "1.2332072774229252\n",
      "FM\n",
      "1.4966064826557828\n",
      "mean\n",
      "1.240828279567413\n"
     ]
    }
   ],
   "source": [
    "# baselines\n",
    "stack_feature_list = ['XGBRegressor', 'XGBClassifier', 'surprise', 'keras', 'FM']\n",
    "pred = []\n",
    "for i in stack_feature_list:\n",
    "    print (i)\n",
    "    p = train_meta[i].values\n",
    "    print (MAE(p, train_meta['Book-Rating'].values))\n",
    "    pred.append(p)\n",
    "    \n",
    "pred = np.round(np.mean(pred, 0))\n",
    "print ('mean')\n",
    "print (MAE(pred, train_meta['Book-Rating'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 , data length: 208161\n",
      "\t validation score: 1.2165984512211525\n",
      "fold 2 , data length: 208161\n",
      "\t validation score: 1.215138064218597\n",
      "fold 3 , data length: 208162\n",
      "\t validation score: 1.2186971560338202\n",
      "fold 4 , data length: 208162\n",
      "\t validation score: 1.2164296694850116\n",
      "fold 5 , data length: 208162\n",
      "\t validation score: 1.2193889315910837\n",
      "mean: 1.217250454509933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR, LinearSVC\n",
    "stack_feature_list = ['XGBRegressor', 'XGBClassifier', 'surprise', 'keras', 'FM']\n",
    "mean = 0\n",
    "for f in range(5):\n",
    "    train_fold = train_meta[train_meta.foldID != f+1]\n",
    "    val_fold = train_meta[train_meta.foldID == f+1]\n",
    "\n",
    "    x_train, y_train = train_fold[stack_feature_list], train_fold['Book-Rating']\n",
    "    x_val, y_val = val_fold[stack_feature_list], val_fold['Book-Rating']\n",
    "    \n",
    "    print (\"fold\", f+1, ', data length:', len(x_train))\n",
    "    model = LinearSVR()\n",
    "    model.fit(x_train, y_train)\n",
    "    pred = model.predict(x_val)\n",
    "    pred = np.round(pred)\n",
    "    mae = MAE(pred, y_val)\n",
    "    mean += mae\n",
    "    print (\"\\t\", 'validation score:', mae)\n",
    "\n",
    "print ('mean:', mean/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 , data length: 208161\n",
      "\t validation score: 1.2165984512211525\n",
      "fold 2 , data length: 208161\n",
      "\t validation score: 1.215138064218597\n",
      "fold 3 , data length: 208162\n",
      "\t validation score: 1.2186971560338202\n",
      "fold 4 , data length: 208162\n",
      "\t validation score: 1.2164296694850116\n",
      "fold 5 , data length: 208162\n",
      "\t validation score: 1.2193889315910837\n",
      "mean: 1.217250454509933\n"
     ]
    }
   ],
   "source": [
    "from keras import \n",
    "stack_feature_list = ['XGBRegressor', 'XGBClassifier', 'surprise', 'keras', 'FM']\n",
    "mean = 0\n",
    "for f in range(5):\n",
    "    train_fold = train_meta[train_meta.foldID != f+1]\n",
    "    val_fold = train_meta[train_meta.foldID == f+1]\n",
    "\n",
    "    x_train, y_train = train_fold[stack_feature_list], train_fold['Book-Rating']\n",
    "    x_val, y_val = val_fold[stack_feature_list], val_fold['Book-Rating']\n",
    "    \n",
    "    print (\"fold\", f+1, ', data length:', len(x_train))\n",
    "    model = LinearSVR()\n",
    "    model.fit(x_train, y_train)\n",
    "    pred = model.predict(x_val)\n",
    "    pred = np.round(pred)\n",
    "    mae = MAE(pred, y_val)\n",
    "    mean += mae\n",
    "    print (\"\\t\", 'validation score:', mae)\n",
    "\n",
    "print ('mean:', mean/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 , data length: 208161\n",
      "\t validation score: 1.2150996329816874\n",
      "fold 2 , data length: 208161\n",
      "\t validation score: 1.2153878672585077\n",
      "fold 3 , data length: 208162\n",
      "\t validation score: 1.2186779400461183\n",
      "fold 4 , data length: 208162\n",
      "\t validation score: 1.216967717140661\n",
      "fold 5 , data length: 208162\n",
      "\t validation score: 1.219369715603382\n",
      "mean: 1.2171005746060712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR, LinearSVC\n",
    "stack_feature_list = ['XGBRegressor', 'XGBClassifier', 'surprise', 'keras', 'FM']\n",
    "mean = 0\n",
    "for f in range(5):\n",
    "    train_fold = train_meta[train_meta.foldID != f+1]\n",
    "    val_fold = train_meta[train_meta.foldID == f+1]\n",
    "\n",
    "    x_train, y_train = train_fold[stack_feature_list], train_fold['Book-Rating']\n",
    "    x_val, y_val = val_fold[stack_feature_list], val_fold['Book-Rating']\n",
    "    \n",
    "    print (\"fold\", f+1, ', data length:', len(x_train))\n",
    "    \n",
    "    model = LinearSVR()\n",
    "    model.fit(x_train, y_train)\n",
    "    pred = model.predict(x_val)\n",
    "    pred = np.round(pred)\n",
    "    mae = MAE(pred, y_val)\n",
    "    mean += mae\n",
    "    print (\"\\t\", 'validation score:', mae)\n",
    "\n",
    "print ('mean:', mean/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>age</th>\n",
       "      <th>loc</th>\n",
       "      <th>author</th>\n",
       "      <th>years</th>\n",
       "      <th>publisher</th>\n",
       "      <th>foldID</th>\n",
       "      <th>surprise</th>\n",
       "      <th>FM</th>\n",
       "      <th>keras</th>\n",
       "      <th>XGBRegressor</th>\n",
       "      <th>XGBClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>133745</td>\n",
       "      <td>6329</td>\n",
       "      <td>47.0</td>\n",
       "      <td>18959</td>\n",
       "      <td>41855</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>560</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>21147</td>\n",
       "      <td>75160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9894</td>\n",
       "      <td>37869</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4132</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>13559</td>\n",
       "      <td>886</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4962</td>\n",
       "      <td>62104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11567</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>31266</td>\n",
       "      <td>57887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15860</td>\n",
       "      <td>45272</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>2678</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>80349</td>\n",
       "      <td>46556</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8588</td>\n",
       "      <td>11258</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>4553</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Book-Rating    ISBN  User-ID   age    loc  author   years  publisher  \\\n",
       "0          8.0  133745     6329  47.0  18959   41855  1992.0        560   \n",
       "1         10.0   21147    75160   0.0   9894   37869  2001.0       4132   \n",
       "2          8.0   13559      886  29.0   4962   62104     0.0      11567   \n",
       "3         10.0   31266    57887   0.0  15860   45272  1997.0       2678   \n",
       "4          9.0   80349    46556  45.0   8588   11258  2000.0       4553   \n",
       "\n",
       "   foldID  surprise   FM  keras  XGBRegressor  XGBClassifier  \n",
       "0       3       7.0  7.0      8             7              7  \n",
       "1       3       8.0  7.0      8             8              8  \n",
       "2       4       8.0  8.0      8             8              8  \n",
       "3       5       8.0  7.0      8             7              8  \n",
       "4       4      10.0  8.0     10             9             10  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta.to_csv('stack/train_meta3.csv')\n",
    "test_meta.to_csv('stack/test_meta3.csv')\n",
    "train_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "def my_mae(ground, preds):\n",
    "    return MAE(ground, np.round(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('XGBRegressor',), ('XGBClassifier',), ('surprise',), ('keras',), ('FM',), ('XGBRegressor', 'XGBClassifier'), ('XGBRegressor', 'surprise'), ('XGBRegressor', 'keras'), ('XGBRegressor', 'FM'), ('XGBClassifier', 'surprise'), ('XGBClassifier', 'keras'), ('XGBClassifier', 'FM'), ('surprise', 'keras'), ('surprise', 'FM'), ('keras', 'FM'), ('XGBRegressor', 'XGBClassifier', 'surprise'), ('XGBRegressor', 'XGBClassifier', 'keras'), ('XGBRegressor', 'XGBClassifier', 'FM'), ('XGBRegressor', 'surprise', 'keras'), ('XGBRegressor', 'surprise', 'FM'), ('XGBRegressor', 'keras', 'FM'), ('XGBClassifier', 'surprise', 'keras'), ('XGBClassifier', 'surprise', 'FM'), ('XGBClassifier', 'keras', 'FM'), ('surprise', 'keras', 'FM'), ('XGBRegressor', 'XGBClassifier', 'surprise', 'keras'), ('XGBRegressor', 'XGBClassifier', 'surprise', 'FM'), ('XGBRegressor', 'XGBClassifier', 'keras', 'FM'), ('XGBRegressor', 'surprise', 'keras', 'FM'), ('XGBClassifier', 'surprise', 'keras', 'FM')]\n"
     ]
    }
   ],
   "source": [
    "# create combinations of features\n",
    "from itertools import combinations\n",
    "all_combin = []\n",
    "for k in range(1, len(stack_feature_list)):\n",
    "    for j in combinations(stack_feature_list, k):\n",
    "        all_combin.append(j)\n",
    "\n",
    "print (all_combin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['XGBRegressor']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    4.2s remaining:    6.3s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2264433017424923 1.2264433017424923\n",
      "['XGBClassifier']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    5.8s remaining:    8.8s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.266796565745075 1.2264433017424923\n",
      "['surprise']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    4.7s remaining:    7.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2186493570379935\n",
      "['keras']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    5.0s remaining:    7.6s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2332072774229252 1.2186493570379935\n",
      "['FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    2.7s remaining:    4.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.434985126939839 1.2186493570379935\n",
      "['XGBRegressor', 'XGBClassifier']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   11.1s remaining:   16.6s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   12.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2264433017424923 1.2186493570379935\n",
      "['XGBRegressor', 'surprise']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   10.3s remaining:   15.4s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   12.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2186493570379935\n",
      "['XGBRegressor', 'keras']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   11.6s remaining:   17.4s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   14.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2213242019661648 1.2186493570379935\n",
      "['XGBRegressor', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    5.7s remaining:    8.6s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2264433017424923 1.2186493570379935\n",
      "['XGBClassifier', 'surprise']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   10.9s remaining:   16.4s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   12.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2186493570379935\n",
      "['XGBClassifier', 'keras']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   18.1s remaining:   27.1s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   20.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2332072774229252 1.2186493570379935\n",
      "['XGBClassifier', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   10.7s remaining:   16.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   11.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.266796565745075 1.2186493570379935\n",
      "['surprise', 'keras']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   10.1s remaining:   15.2s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   10.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2186493570379935\n",
      "['surprise', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    6.3s remaining:    9.5s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    7.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2186493570379935\n",
      "['keras', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    7.8s remaining:   11.7s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2332072774229252 1.2186493570379935\n",
      "['XGBRegressor', 'XGBClassifier', 'surprise']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   19.9s remaining:   29.9s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   24.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2186493570379935\n",
      "['XGBRegressor', 'XGBClassifier', 'keras']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   19.4s remaining:   29.2s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   21.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2227423309582555 1.2186493570379935\n",
      "['XGBRegressor', 'XGBClassifier', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   20.4s remaining:   30.6s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   21.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2264433017424923 1.2186493570379935\n",
      "['XGBRegressor', 'surprise', 'keras']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   23.6s remaining:   35.4s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   24.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2186493570379935\n",
      "['XGBRegressor', 'surprise', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   18.9s remaining:   28.3s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   20.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2186493570379935\n",
      "['XGBRegressor', 'keras', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   19.7s remaining:   29.6s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   20.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.223672377614315 1.2186493570379935\n",
      "['XGBClassifier', 'surprise', 'keras']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   21.0s remaining:   31.5s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   21.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2186493570379935\n",
      "['XGBClassifier', 'surprise', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   18.8s remaining:   28.2s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   20.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2186493570379935\n",
      "['XGBClassifier', 'keras', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   24.5s remaining:   36.8s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   25.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2332072774229252 1.2186493570379935\n",
      "['surprise', 'keras', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   15.2s remaining:   22.7s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   16.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2186493570379935\n",
      "['XGBRegressor', 'XGBClassifier', 'surprise', 'keras']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   28.0s remaining:   42.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   28.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2184495123019807 1.2184495123019807\n",
      "['XGBRegressor', 'XGBClassifier', 'surprise', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   27.1s remaining:   40.6s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   27.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2184495123019807\n",
      "['XGBRegressor', 'XGBClassifier', 'keras', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   26.0s remaining:   39.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   26.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2144564607497252 1.2144564607497252\n",
      "['XGBRegressor', 'surprise', 'keras', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   25.9s remaining:   38.9s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   27.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2144564607497252\n",
      "['XGBClassifier', 'surprise', 'keras', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   27.8s remaining:   41.7s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   28.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2144564607497252\n",
      "1.2144564607497252 ('XGBRegressor', 'XGBClassifier', 'keras', 'FM')\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "best_score = 99\n",
    "best_com = \"\"\n",
    "\n",
    "for com in all_combin:\n",
    "    \n",
    "    stack_feature_list = [i for i in com]\n",
    "    print (stack_feature_list)\n",
    "\n",
    "    S = LinearSVR()\n",
    "    \n",
    "    grid = grid_search.GridSearchCV(S,\n",
    "                            parameters,\n",
    "                            cv = 5,\n",
    "                            n_jobs = 5,\n",
    "                            scoring = make_scorer(my_mae, greater_is_better=False),\n",
    "                            verbose=True)\n",
    "\n",
    "    grid.fit(train_meta[stack_feature_list], train_meta['Book-Rating'])\n",
    "\n",
    "    if -grid.best_score_ < best_score:\n",
    "        best_score = -grid.best_score_\n",
    "        best_com = com\n",
    "    print (-grid.best_score_ , best_score)\n",
    "    \n",
    "print (best_score, best_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['XGBRegressor', 'XGBClassifier', 'keras', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   25.5s remaining:   38.2s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   26.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.21374931783768\n",
      "{'C': 1}\n",
      "[mean: -1.21375, std: 0.00942, params: {'C': 1}]\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters grid search\n",
    "stack_feature_list = [i for i in best_com]\n",
    "print (stack_feature_list)\n",
    "S = LinearSVR()\n",
    "#parameters = {'C':[0.01, 0.1, 1, 10]}\n",
    "parameters = {'C':[1]}\n",
    "grid = grid_search.GridSearchCV(S,\n",
    "                        parameters,\n",
    "                        cv = 5,\n",
    "                        n_jobs = 5,\n",
    "                        scoring = make_scorer(my_mae, greater_is_better=False),\n",
    "                        verbose=True)\n",
    "\n",
    "grid.fit(train_meta[stack_feature_list], train_meta['Book-Rating'])\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no feature importance\n"
     ]
    }
   ],
   "source": [
    "# fit on all train data\n",
    "stack_feature_list = [i for i in best_com]\n",
    "S = LinearSVR(grid.best_params_)\n",
    "S.fit(train_meta[stack_feature_list], train_meta['Book-Rating'])\n",
    "plot_importance(S, stack_feature_list)\n",
    "final_pred = S.predict(test_meta[stack_feature_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stack/stack.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(model, 'stack/stack.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output\n",
    "with open('stack/final.csv', 'w') as f:\n",
    "    for i in final_pred:\n",
    "        print (int(round(i)), file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
