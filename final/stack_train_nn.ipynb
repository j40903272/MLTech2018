{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dada/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/dada/.local/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn import cross_validation, grid_search, metrics, ensemble\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>age</th>\n",
       "      <th>loc</th>\n",
       "      <th>author</th>\n",
       "      <th>years</th>\n",
       "      <th>publisher</th>\n",
       "      <th>foldID</th>\n",
       "      <th>surprise</th>\n",
       "      <th>FM</th>\n",
       "      <th>keras</th>\n",
       "      <th>XGBRegressor</th>\n",
       "      <th>XGBClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>133745</td>\n",
       "      <td>6329</td>\n",
       "      <td>47.0</td>\n",
       "      <td>18959</td>\n",
       "      <td>41855</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>560</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>21147</td>\n",
       "      <td>75160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9894</td>\n",
       "      <td>37869</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4132</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>13559</td>\n",
       "      <td>886</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4962</td>\n",
       "      <td>62104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11567</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>31266</td>\n",
       "      <td>57887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15860</td>\n",
       "      <td>45272</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>2678</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>80349</td>\n",
       "      <td>46556</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8588</td>\n",
       "      <td>11258</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>4553</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Book-Rating    ISBN  User-ID   age    loc  author   years  publisher  \\\n",
       "0          8.0  133745     6329  47.0  18959   41855  1992.0        560   \n",
       "1         10.0   21147    75160   0.0   9894   37869  2001.0       4132   \n",
       "2          8.0   13559      886  29.0   4962   62104     0.0      11567   \n",
       "3         10.0   31266    57887   0.0  15860   45272  1997.0       2678   \n",
       "4          9.0   80349    46556  45.0   8588   11258  2000.0       4553   \n",
       "\n",
       "   foldID  surprise   FM  keras  XGBRegressor  XGBClassifier  \n",
       "0       3       7.0  7.0      8             7              7  \n",
       "1       3       8.0  7.0      8             8              8  \n",
       "2       4       8.0  8.0      8             8              8  \n",
       "3       5       8.0  7.0      8             7              8  \n",
       "4       4      10.0  8.0     10             9             10  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ttt = pd.read_csv('../../merge.csv')\n",
    "train_meta = pd.read_csv('../../stack/train_meta3.csv')\n",
    "test_meta = pd.read_csv('../../stack/test_meta3.csv')\n",
    "train_meta = train_meta.drop(columns=['Unnamed: 0'])\n",
    "test_meta = test_meta.drop(columns=['Unnamed: 0'])\n",
    "train_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdUAAAFwCAYAAADuaOGqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUUmCakRERCX/AAgOjavEnfH0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=[7,5])\n",
    "sns.heatmap(train_meta.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>age</th>\n",
       "      <th>loc</th>\n",
       "      <th>author</th>\n",
       "      <th>years</th>\n",
       "      <th>publisher</th>\n",
       "      <th>foldID</th>\n",
       "      <th>surprise</th>\n",
       "      <th>FM</th>\n",
       "      <th>keras</th>\n",
       "      <th>XGBRegressor</th>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>133745</td>\n",
       "      <td>6329</td>\n",
       "      <td>47.0</td>\n",
       "      <td>18959</td>\n",
       "      <td>41855</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>560</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>21147</td>\n",
       "      <td>75160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9894</td>\n",
       "      <td>37869</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4132</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>13559</td>\n",
       "      <td>886</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4962</td>\n",
       "      <td>62104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11567</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>31266</td>\n",
       "      <td>57887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15860</td>\n",
       "      <td>45272</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>2678</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>80349</td>\n",
       "      <td>46556</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8588</td>\n",
       "      <td>11258</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>4553</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Book-Rating    ISBN  User-ID   age    loc  author   years  publisher  \\\n",
       "0          8.0  133745     6329  47.0  18959   41855  1992.0        560   \n",
       "1         10.0   21147    75160   0.0   9894   37869  2001.0       4132   \n",
       "2          8.0   13559      886  29.0   4962   62104     0.0      11567   \n",
       "3         10.0   31266    57887   0.0  15860   45272  1997.0       2678   \n",
       "4          9.0   80349    46556  45.0   8588   11258  2000.0       4553   \n",
       "\n",
       "   foldID  surprise   FM  keras  XGBRegressor  XGBClassifier  nn  \n",
       "0       3       7.0  7.0      8             7              7 NaN  \n",
       "1       3       8.0  7.0      8             8              8 NaN  \n",
       "2       4       8.0  8.0      8             8              8 NaN  \n",
       "3       5       8.0  7.0      8             7              8 NaN  \n",
       "4       4      10.0  8.0     10             9             10 NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta['nn'] = float('nan')\n",
    "test_meta['nn'] = float('nan')\n",
    "train_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_users = ttt['User-ID'].nunique()\n",
    "n_books = ttt['ISBN'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 , data length: 208161\n",
      "validation score: 1.2156953171537825\n",
      "fold 2 , data length: 208161\n",
      "validation score: 1.2173862915777944\n",
      "fold 3 , data length: 208162\n",
      "validation score: 1.2192352036894696\n",
      "fold 4 , data length: 208162\n",
      "validation score: 1.217044581091468\n",
      "fold 5 , data length: 208162\n",
      "validation score: 1.2199846272098387\n",
      "mean: 1.2178692041444708\n"
     ]
    }
   ],
   "source": [
    "# train and fill train meta\n",
    "mean = 0\n",
    "for f in range(5):\n",
    "    train_fold = train_meta[train_meta.foldID != f+1]\n",
    "    val_fold = train_meta[train_meta.foldID == f+1]\n",
    "    \n",
    "    user_train, book_train, rate_train = train_fold['User-ID'].values, train_fold['ISBN'].values, train_fold['Book-Rating'].values\n",
    "    user_val, book_val, rate_val = val_fold['User-ID'].values, val_fold['ISBN'].values, val_fold['Book-Rating'].values\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "            dataset=TensorDataset(\n",
    "                torch.from_numpy(user_train),\n",
    "                torch.from_numpy(book_train),\n",
    "                torch.from_numpy(rate_train)),\n",
    "            batch_size=1024,\n",
    "            shuffle=True,\n",
    "            num_workers=8)\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "            dataset=TensorDataset(\n",
    "                torch.from_numpy(user_val),\n",
    "                torch.from_numpy(book_val),\n",
    "                torch.from_numpy(rate_val)),\n",
    "            batch_size=1024,\n",
    "            num_workers=8)\n",
    "    \n",
    "    print (\"fold\", f+1, ', data length:', len(user_train))\n",
    "    \n",
    "    global_mean = rate_train.mean().item()\n",
    "    model = Model(\n",
    "            user_size = n_users + 1,\n",
    "            book_size = n_books + 1,\n",
    "            global_mean=global_mean).cuda()\n",
    "    \n",
    "    optimizer_u = torch.optim.SGD(model.user_bias.parameters(), lr=0.01)\n",
    "    optimizer_b = torch.optim.SGD(model.book_bias.parameters(), lr=0.005)\n",
    "    \n",
    "    for epoch in range(45):\n",
    "        print ('Epoch:', epoch, end='\\r')\n",
    "        for i ,(user, book, rate) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            user, book, rate = user.cuda(), book.cuda(), rate.cuda()\n",
    "            output, reg_loss = model(user, book)\n",
    "\n",
    "            # MAE Loss\n",
    "            loss = F.l1_loss(output, rate.float(), size_average=False)\n",
    "            # MAPE Loss\n",
    "            #loss = (F.l1_loss(output, rate, reduce=False) / rate).sum()\n",
    "\n",
    "            optimizer_u.zero_grad()\n",
    "            optimizer_b.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_u.step()\n",
    "            optimizer_b.step()\n",
    "            \n",
    "            \n",
    "    model.eval()\n",
    "    pred = []\n",
    "    for i ,(user, book, rate) in enumerate(val_loader):\n",
    "        user, book= user.cuda(), book.cuda()\n",
    "        output = model(user, book, test=True)\n",
    "        pred.append(output.detach().cpu().numpy())\n",
    "\n",
    "    pred = np.hstack(pred)\n",
    "    pred = np.round(pred)\n",
    "    mae = MAE(pred, rate_val)\n",
    "    mean += mae\n",
    "    print ('validation score:', mae)\n",
    "        \n",
    "    train_meta['nn'][train_meta.foldID == f+1] = pred.astype(int)\n",
    "\n",
    "print ('mean:', mean/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44\r"
     ]
    }
   ],
   "source": [
    "# train on all and fill test meta\n",
    "user_train, book_train, rate_train = train_meta['User-ID'].values, train_meta['ISBN'].values, train_meta['Book-Rating'].values\n",
    "user_test, book_test = test_meta['User-ID'].values, test_meta['ISBN'].values\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        dataset=TensorDataset(\n",
    "            torch.from_numpy(user_train),\n",
    "            torch.from_numpy(book_train),\n",
    "            torch.from_numpy(rate_train)),\n",
    "        batch_size=1024,\n",
    "        shuffle=True,\n",
    "        num_workers=8)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        dataset=TensorDataset(\n",
    "            torch.from_numpy(user_test),\n",
    "            torch.from_numpy(book_test)),\n",
    "        batch_size=1024,\n",
    "        num_workers=8)\n",
    "\n",
    "\n",
    "global_mean = rate_train.mean().item()\n",
    "model = Model(\n",
    "        user_size = n_users + 1,\n",
    "        book_size = n_books + 1,\n",
    "        global_mean=global_mean).cuda()\n",
    "\n",
    "optimizer_u = torch.optim.SGD(model.user_bias.parameters(), lr=0.01)\n",
    "optimizer_b = torch.optim.SGD(model.book_bias.parameters(), lr=0.005)\n",
    "\n",
    "for epoch in range(45):\n",
    "    print ('Epoch:', epoch, end='\\r')\n",
    "    for i ,(user, book, rate) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        user, book, rate = user.cuda(), book.cuda(), rate.cuda()\n",
    "        output, reg_loss = model(user, book)\n",
    "\n",
    "        # MAE Loss\n",
    "        loss = F.l1_loss(output, rate.float(), size_average=False)\n",
    "        # MAPE Loss\n",
    "        #loss = (F.l1_loss(output, rate, reduce=False) / rate).sum()\n",
    "\n",
    "        optimizer_u.zero_grad()\n",
    "        optimizer_b.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_u.step()\n",
    "        optimizer_b.step()\n",
    "\n",
    "\n",
    "model.eval()\n",
    "pred = []\n",
    "for i ,(user, book) in enumerate(test_loader):\n",
    "    user, book= user.cuda(), book.cuda()\n",
    "    output = model(user, book, test=True)\n",
    "    pred.append(output.detach().cpu().numpy())\n",
    "\n",
    "pred = np.hstack(pred)\n",
    "pred = np.round(pred)\n",
    "test_meta['nn'] = pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>age</th>\n",
       "      <th>loc</th>\n",
       "      <th>author</th>\n",
       "      <th>years</th>\n",
       "      <th>publisher</th>\n",
       "      <th>foldID</th>\n",
       "      <th>surprise</th>\n",
       "      <th>FM</th>\n",
       "      <th>keras</th>\n",
       "      <th>XGBRegressor</th>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>133745</td>\n",
       "      <td>6329</td>\n",
       "      <td>47.0</td>\n",
       "      <td>18959</td>\n",
       "      <td>41855</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>560</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>21147</td>\n",
       "      <td>75160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9894</td>\n",
       "      <td>37869</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4132</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>13559</td>\n",
       "      <td>886</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4962</td>\n",
       "      <td>62104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11567</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>31266</td>\n",
       "      <td>57887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15860</td>\n",
       "      <td>45272</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>2678</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>80349</td>\n",
       "      <td>46556</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8588</td>\n",
       "      <td>11258</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>4553</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Book-Rating    ISBN  User-ID   age    loc  author   years  publisher  \\\n",
       "0          8.0  133745     6329  47.0  18959   41855  1992.0        560   \n",
       "1         10.0   21147    75160   0.0   9894   37869  2001.0       4132   \n",
       "2          8.0   13559      886  29.0   4962   62104     0.0      11567   \n",
       "3         10.0   31266    57887   0.0  15860   45272  1997.0       2678   \n",
       "4          9.0   80349    46556  45.0   8588   11258  2000.0       4553   \n",
       "\n",
       "   foldID  surprise   FM  keras  XGBRegressor  XGBClassifier    nn  \n",
       "0       3       7.0  7.0      8             7              7   7.0  \n",
       "1       3       8.0  7.0      8             8              8   8.0  \n",
       "2       4       8.0  8.0      8             8              8   8.0  \n",
       "3       5       8.0  7.0      8             7              8   8.0  \n",
       "4       4      10.0  8.0     10             9             10  10.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta.to_csv('nn_train_meta3.csv')\n",
    "test_meta.to_csv('nn_test_meta3.csv')\n",
    "train_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor\n",
      "1.2264433017424923\n",
      "XGBClassifier\n",
      "1.266796565745075\n",
      "surprise\n",
      "1.2186493570379935\n",
      "keras\n",
      "1.2332072774229252\n",
      "FM\n",
      "1.4966064826557828\n",
      "nn\n",
      "1.2178691939339437\n",
      "mean\n",
      "1.231470165486814\n"
     ]
    }
   ],
   "source": [
    "# baselines\n",
    "stack_feature_list = ['XGBRegressor', 'XGBClassifier', 'surprise', 'keras', 'FM', 'nn']\n",
    "pred = []\n",
    "for i in stack_feature_list:\n",
    "    print (i)\n",
    "    p = train_meta[i].values\n",
    "    print (MAE(p, train_meta['Book-Rating'].values))\n",
    "    pred.append(p)\n",
    "    \n",
    "pred = np.round(np.mean(pred, 0))\n",
    "print ('mean')\n",
    "print (MAE(pred, train_meta['Book-Rating'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 , data length: 208161\n",
      "\t validation score: 1.2160604139044215\n",
      "fold 2 , data length: 208161\n",
      "\t validation score: 1.2087776945100979\n",
      "fold 3 , data length: 208162\n",
      "\t validation score: 1.2133743274404305\n",
      "fold 4 , data length: 208162\n",
      "\t validation score: 1.2098001537279015\n",
      "fold 5 , data length: 208162\n",
      "\t validation score: 1.2126825518831668\n",
      "mean: 1.2121390282932034\n"
     ]
    }
   ],
   "source": [
    "# test stack model\n",
    "from sklearn.svm import LinearSVR\n",
    "stack_feature_list = ['XGBRegressor', 'XGBClassifier', 'surprise', 'keras', 'FM', 'nn']\n",
    "mean = 0\n",
    "for f in range(5):\n",
    "    train_fold = train_meta[train_meta.foldID != f+1]\n",
    "    val_fold = train_meta[train_meta.foldID == f+1]\n",
    "\n",
    "    x_train, y_train = train_fold[stack_feature_list], train_fold['Book-Rating']\n",
    "    x_val, y_val = val_fold[stack_feature_list], val_fold['Book-Rating']\n",
    "    \n",
    "    print (\"fold\", f+1, ', data length:', len(x_train))\n",
    "    model = LinearSVR()\n",
    "    model.fit(x_train, y_train)\n",
    "    pred = model.predict(x_val)\n",
    "    pred = np.round(pred)\n",
    "    mae = MAE(pred, y_val)\n",
    "    mean += mae\n",
    "    print (\"\\t\", 'validation score:', mae)\n",
    "\n",
    "print ('mean:', mean/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "def my_mae(ground, preds):\n",
    "    return MAE(ground, np.round(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('XGBRegressor',)\n",
      "('XGBClassifier',)\n",
      "('surprise',)\n",
      "('keras',)\n",
      "('FM',)\n",
      "('nn',)\n",
      "('XGBRegressor', 'XGBClassifier')\n",
      "('XGBRegressor', 'surprise')\n",
      "('XGBRegressor', 'keras')\n",
      "('XGBRegressor', 'FM')\n",
      "('XGBRegressor', 'nn')\n",
      "('XGBClassifier', 'surprise')\n",
      "('XGBClassifier', 'keras')\n",
      "('XGBClassifier', 'FM')\n",
      "('XGBClassifier', 'nn')\n",
      "('surprise', 'keras')\n",
      "('surprise', 'FM')\n",
      "('surprise', 'nn')\n",
      "('keras', 'FM')\n",
      "('keras', 'nn')\n",
      "('FM', 'nn')\n",
      "('XGBRegressor', 'XGBClassifier', 'surprise')\n",
      "('XGBRegressor', 'XGBClassifier', 'keras')\n",
      "('XGBRegressor', 'XGBClassifier', 'FM')\n",
      "('XGBRegressor', 'XGBClassifier', 'nn')\n",
      "('XGBRegressor', 'surprise', 'keras')\n",
      "('XGBRegressor', 'surprise', 'FM')\n",
      "('XGBRegressor', 'surprise', 'nn')\n",
      "('XGBRegressor', 'keras', 'FM')\n",
      "('XGBRegressor', 'keras', 'nn')\n",
      "('XGBRegressor', 'FM', 'nn')\n",
      "('XGBClassifier', 'surprise', 'keras')\n",
      "('XGBClassifier', 'surprise', 'FM')\n",
      "('XGBClassifier', 'surprise', 'nn')\n",
      "('XGBClassifier', 'keras', 'FM')\n",
      "('XGBClassifier', 'keras', 'nn')\n",
      "('XGBClassifier', 'FM', 'nn')\n",
      "('surprise', 'keras', 'FM')\n",
      "('surprise', 'keras', 'nn')\n",
      "('surprise', 'FM', 'nn')\n",
      "('keras', 'FM', 'nn')\n",
      "('XGBRegressor', 'XGBClassifier', 'surprise', 'keras')\n",
      "('XGBRegressor', 'XGBClassifier', 'surprise', 'FM')\n",
      "('XGBRegressor', 'XGBClassifier', 'surprise', 'nn')\n",
      "('XGBRegressor', 'XGBClassifier', 'keras', 'FM')\n",
      "('XGBRegressor', 'XGBClassifier', 'keras', 'nn')\n",
      "('XGBRegressor', 'XGBClassifier', 'FM', 'nn')\n",
      "('XGBRegressor', 'surprise', 'keras', 'FM')\n",
      "('XGBRegressor', 'surprise', 'keras', 'nn')\n",
      "('XGBRegressor', 'surprise', 'FM', 'nn')\n",
      "('XGBRegressor', 'keras', 'FM', 'nn')\n",
      "('XGBClassifier', 'surprise', 'keras', 'FM')\n",
      "('XGBClassifier', 'surprise', 'keras', 'nn')\n",
      "('XGBClassifier', 'surprise', 'FM', 'nn')\n",
      "('XGBClassifier', 'keras', 'FM', 'nn')\n",
      "('surprise', 'keras', 'FM', 'nn')\n",
      "('XGBRegressor', 'XGBClassifier', 'surprise', 'keras', 'FM')\n",
      "('XGBRegressor', 'XGBClassifier', 'surprise', 'keras', 'nn')\n",
      "('XGBRegressor', 'XGBClassifier', 'surprise', 'FM', 'nn')\n",
      "('XGBRegressor', 'XGBClassifier', 'keras', 'FM', 'nn')\n",
      "('XGBRegressor', 'surprise', 'keras', 'FM', 'nn')\n",
      "('XGBClassifier', 'surprise', 'keras', 'FM', 'nn')\n"
     ]
    }
   ],
   "source": [
    "# create combinations of features\n",
    "from itertools import combinations\n",
    "all_combin = []\n",
    "for k in range(1, len(stack_feature_list)+1):\n",
    "    for j in combinations(stack_feature_list, k):\n",
    "        all_combin.append(j)\n",
    "\n",
    "for i in all_combin:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['XGBRegressor']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    4.0s remaining:    6.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2264433017424923 1.2264433017424923\n",
      "['XGBClassifier']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    5.7s remaining:    8.5s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    6.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.266796565745075 1.2264433017424923\n",
      "['surprise']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    4.3s remaining:    6.5s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2186493570379935\n",
      "['keras']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    5.0s remaining:    7.4s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2332072774229252 1.2186493570379935\n",
      "['FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    3.4s remaining:    5.1s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.434985126939839 1.2186493570379935\n",
      "['nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    5.4s remaining:    8.1s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.2178691939339437\n",
      "['XGBRegressor', 'XGBClassifier']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   12.8s remaining:   19.2s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   14.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2264433017424923 1.2178691939339437\n",
      "['XGBRegressor', 'surprise']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   13.4s remaining:   20.1s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   14.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2178691939339437\n",
      "['XGBRegressor', 'keras']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   14.3s remaining:   21.4s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   15.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.223672377614315 1.2178691939339437\n",
      "['XGBRegressor', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    7.5s remaining:   11.3s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    8.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2264433017424923 1.2178691939339437\n",
      "['XGBRegressor', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   16.1s remaining:   24.1s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   16.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.2178691939339437\n",
      "['XGBClassifier', 'surprise']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   12.9s remaining:   19.3s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   13.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2178691939339437\n",
      "['XGBClassifier', 'keras']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   19.5s remaining:   29.3s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   21.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2332072774229252 1.2178691939339437\n",
      "['XGBClassifier', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   10.8s remaining:   16.3s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   11.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.266796565745075 1.2178691939339437\n",
      "['XGBClassifier', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   13.5s remaining:   20.2s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   14.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.2178691939339437\n",
      "['surprise', 'keras']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   10.6s remaining:   15.9s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   11.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2178691939339437\n",
      "['surprise', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    8.2s remaining:   12.2s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2178691939339437\n",
      "['surprise', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   11.8s remaining:   17.7s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   12.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.2178691939339437\n",
      "['keras', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    8.6s remaining:   12.9s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    9.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2332072774229252 1.2178691939339437\n",
      "['keras', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   12.3s remaining:   18.5s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   12.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.2178691939339437\n",
      "['FM', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    9.2s remaining:   13.8s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    9.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.2178691939339437\n",
      "['XGBRegressor', 'XGBClassifier', 'surprise']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   24.1s remaining:   36.1s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   26.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2178691939339437\n",
      "['XGBRegressor', 'XGBClassifier', 'keras']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   20.8s remaining:   31.2s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   22.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2235301803983059 1.2178691939339437\n",
      "['XGBRegressor', 'XGBClassifier', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   19.9s remaining:   29.8s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   21.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2264433017424923 1.2178691939339437\n",
      "['XGBRegressor', 'XGBClassifier', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   23.4s remaining:   35.1s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   24.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.217861507597943 1.217861507597943\n",
      "['XGBRegressor', 'surprise', 'keras']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   23.8s remaining:   35.8s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   25.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.217861507597943\n",
      "['XGBRegressor', 'surprise', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   18.7s remaining:   28.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   19.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.217861507597943\n",
      "['XGBRegressor', 'surprise', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   23.3s remaining:   35.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   24.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.217861507597943\n",
      "['XGBRegressor', 'keras', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   19.9s remaining:   29.9s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   20.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.223672377614315 1.217861507597943\n",
      "['XGBRegressor', 'keras', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   24.0s remaining:   36.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   24.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.217861507597943\n",
      "['XGBRegressor', 'FM', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   20.4s remaining:   30.5s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   22.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.217861507597943\n",
      "['XGBClassifier', 'surprise', 'keras']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   19.8s remaining:   29.7s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   21.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.217861507597943\n",
      "['XGBClassifier', 'surprise', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   18.9s remaining:   28.4s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   23.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.217861507597943\n",
      "['XGBClassifier', 'surprise', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   21.4s remaining:   32.1s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   22.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.217861507597943\n",
      "['XGBClassifier', 'keras', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   23.9s remaining:   35.9s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   25.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2332072774229252 1.217861507597943\n",
      "['XGBClassifier', 'keras', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   22.3s remaining:   33.5s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   23.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.217861507597943\n",
      "['XGBClassifier', 'FM', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   20.2s remaining:   30.2s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   22.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.217861507597943\n",
      "['surprise', 'keras', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   15.0s remaining:   22.6s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   16.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.217861507597943\n",
      "['surprise', 'keras', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   19.7s remaining:   29.5s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   20.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.217861507597943\n",
      "['surprise', 'FM', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   16.8s remaining:   25.1s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   18.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.217861507597943\n",
      "['keras', 'FM', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   17.0s remaining:   25.5s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   17.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.217861507597943\n",
      "['XGBRegressor', 'XGBClassifier', 'surprise', 'keras']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   28.5s remaining:   42.7s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   29.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2184264532939793 1.217861507597943\n",
      "['XGBRegressor', 'XGBClassifier', 'surprise', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   27.6s remaining:   41.5s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   28.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.217861507597943\n",
      "['XGBRegressor', 'XGBClassifier', 'surprise', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   29.3s remaining:   44.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   30.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2173887979339129 1.2173887979339129\n",
      "['XGBRegressor', 'XGBClassifier', 'keras', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   27.6s remaining:   41.4s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   27.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2157977263818112 1.2157977263818112\n",
      "['XGBRegressor', 'XGBClassifier', 'keras', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   27.0s remaining:   40.5s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   29.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.216750832045872 1.2157977263818112\n",
      "['XGBRegressor', 'XGBClassifier', 'FM', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   25.1s remaining:   37.6s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   27.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2175079361419205 1.2157977263818112\n",
      "['XGBRegressor', 'surprise', 'keras', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   26.2s remaining:   39.3s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   27.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2157977263818112\n",
      "['XGBRegressor', 'surprise', 'keras', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   27.0s remaining:   40.5s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   29.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2172427575499036 1.2157977263818112\n",
      "['XGBRegressor', 'surprise', 'FM', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   25.4s remaining:   38.1s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   26.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2177731147339375 1.2157977263818112\n",
      "['XGBRegressor', 'keras', 'FM', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   25.8s remaining:   38.7s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   27.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.217750055725936 1.2157977263818112\n",
      "['XGBClassifier', 'surprise', 'keras', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   28.0s remaining:   42.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   29.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2186493570379935 1.2157977263818112\n",
      "['XGBClassifier', 'surprise', 'keras', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   28.6s remaining:   42.9s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   29.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.2157977263818112\n",
      "['XGBClassifier', 'surprise', 'FM', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   25.3s remaining:   38.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   27.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.2157977263818112\n",
      "['XGBClassifier', 'keras', 'FM', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   27.9s remaining:   41.9s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   29.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.2157977263818112\n",
      "['surprise', 'keras', 'FM', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   24.7s remaining:   37.1s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   25.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.2157977263818112\n",
      "['XGBRegressor', 'XGBClassifier', 'surprise', 'keras', 'FM']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   30.5s remaining:   45.7s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   31.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2175271519819217 1.2157977263818112\n",
      "['XGBRegressor', 'XGBClassifier', 'surprise', 'keras', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   30.7s remaining:   46.1s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   32.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2127731531656174 1.2127731531656174\n",
      "['XGBRegressor', 'XGBClassifier', 'surprise', 'FM', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   30.3s remaining:   45.5s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   31.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2160513754698272 1.2127731531656174\n",
      "['XGBRegressor', 'XGBClassifier', 'keras', 'FM', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   30.6s remaining:   45.9s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   31.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2135533162696674 1.2127731531656174\n",
      "['XGBRegressor', 'surprise', 'keras', 'FM', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   30.8s remaining:   46.2s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   31.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.216451064941853 1.2127731531656174\n",
      "['XGBClassifier', 'surprise', 'keras', 'FM', 'nn']\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   30.1s remaining:   45.1s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   31.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2178691939339437 1.2127731531656174\n",
      "1.2127731531656174 ('XGBRegressor', 'XGBClassifier', 'surprise', 'keras', 'nn')\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "best_score = 99\n",
    "best_com = \"\"\n",
    "\n",
    "for com in all_combin:\n",
    "    \n",
    "    stack_feature_list = [i for i in com]\n",
    "    print (stack_feature_list)\n",
    "\n",
    "    S = LinearSVR()\n",
    "    parameters = {'C':[1]}\n",
    "    \n",
    "    grid = grid_search.GridSearchCV(S,\n",
    "                            parameters,\n",
    "                            cv = 5,\n",
    "                            n_jobs = 5,\n",
    "                            scoring = make_scorer(my_mae, greater_is_better=False),\n",
    "                            verbose=True)\n",
    "\n",
    "    grid.fit(train_meta[stack_feature_list], train_meta['Book-Rating'])\n",
    "\n",
    "    if -grid.best_score_ < best_score:\n",
    "        best_score = -grid.best_score_\n",
    "        best_com = com\n",
    "    print (-grid.best_score_ , best_score)\n",
    "    \n",
    "print (best_score, best_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  20 out of  20 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.2109169030214988\n",
      "{'C': 1}\n",
      "[mean: -1.21787, std: 0.00527, params: {'C': 0.01}, mean: -1.21787, std: 0.00527, params: {'C': 0.1}, mean: -1.21092, std: 0.00459, params: {'C': 1}, mean: -1.81736, std: 0.48884, params: {'C': 10}]\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters grid search\n",
    "stack_feature_list = [i for i in best_com]\n",
    "S = LinearSVR()\n",
    "parameters = {'C':[0.01, 0.1, 1, 10]}\n",
    "grid = grid_search.GridSearchCV(S,\n",
    "                        parameters,\n",
    "                        cv = 5,\n",
    "                        n_jobs = 5,\n",
    "                        scoring = make_scorer(my_mae, greater_is_better=False),\n",
    "                        verbose=True)\n",
    "\n",
    "grid.fit(train_meta[stack_feature_list], train_meta['Book-Rating'])\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['XGBRegressor', 'XGBClassifier', 'surprise', 'keras', 'FM', 'nn']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stack.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit on all train data\n",
    "print (stack_feature_list)\n",
    "S = LinearSVR(**grid.best_params_)\n",
    "S.fit(train_meta[stack_feature_list], train_meta['Book-Rating'])\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(model, 'stack.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output\n",
    "final_pred = S.predict(test_meta[stack_feature_list])\n",
    "with open('final.csv', 'w') as f:\n",
    "    for i in final_pred:\n",
    "        print (int(round(i)), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_collections = []\n",
    "pred_collections.append(final_pred)\n",
    "\n",
    "for _ in range(20):\n",
    "    S = LinearSVR(**grid.best_params_)\n",
    "    S.fit(train_meta[stack_feature_list], train_meta['Book-Rating'])\n",
    "    pred = S.predict(test_meta[stack_feature_list])\n",
    "    pred_collections.append(pred)\n",
    "\n",
    "pred = np.mean(pred_collections, 0)\n",
    "pred = np.round(pred).astype(int)\n",
    "with open('finals.csv', 'w') as f:\n",
    "    for i in pred:\n",
    "        print (i, file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
